<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.17.2 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>This Goes to Eleven (Pt. 5/∞) - damageboy</title>
<meta name="description" content="Decimating Array.Sort with AVX2. I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics. There’s no reason I should go down alone.">


  <meta name="author" content="damageboy">


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="damageboy">
<meta property="og:title" content="This Goes to Eleven (Pt. 5/∞)">
<meta property="og:url" content="https://bits.houmus.org/2020-02-02/this-goes-to-eleven-pt5">


  <meta property="og:description" content="Decimating Array.Sort with AVX2. I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics. There’s no reason I should go down alone.">



  <meta property="og:image" content="https://bits.houmus.org/assets/images/these-go-to-eleven.jpg">





  <meta property="article:published_time" content="2020-02-02T02:22:28+00:00">






<link rel="canonical" href="https://bits.houmus.org/2020-02-02/this-goes-to-eleven-pt5">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": null,
      "url": "https://bits.houmus.org/"
    
  }
</script>


  <meta name="google-site-verification" content="wcrvaF3e88-Vb6y-9eUTqYaXDMOukzl4c-IdKByS0Xc" />


  <meta name="msvalidate.01" content="6D5AE23298671D95A20FAD7FA3430ABB">




<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="damageboy Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->
<link rel="apple-touch-icon" sizes="180x180" href="/assets/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/favicons/site.webmanifest">
<link rel="mask-icon" href="/assets/favicons/safari-pinned-tab.svg" color="#ba0000">
<link rel="shortcut icon" href="/assets/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="damageboy">
<meta name="application-name" content="damageboy">
<meta name="msapplication-TileColor" content="#ba0000">
<meta name="msapplication-config" content="/assets/favicons/browserconfig.xml">
<meta name="theme-color" content="#ba0000ff">

<!-- <link rel="stylesheet" type="text/css" href="/assets/css/inlineDisqussions.css" /> -->
<script src="/assets/scripts/webfont.js"></script>
<script>
WebFont.load({
  google: {
    families: ['Lato', 'Indie Flower']
  },
  custom: {
    families: ['Cascadia Code'],
    urls: ['/assets/css/cascadia.css']
  }
});
</script>


<script defer src="/assets/scripts/jquery.min.js"></script>
<script defer src="/assets/scripts/polyfill.min.js"></script>
<script defer src="/assets/scripts/config-mathjax.js"></script>
<script defer src="/assets/scripts/tex-chtml-full.js"></script>
<!-- <script defer src="/assets/scripts/inlineDisqussions.js"></script> -->
<script defer src="/assets/scripts/uikit.min.js"></script>
<script defer src="/assets/scripts/uikit-icons.min.js"></script>
<script defer src="/assets/scripts/roughjs@3.1.0"></script>
<script defer src="/assets/scripts/Chart.bundle.min.js"></script>
<script defer src="/assets/scripts/chartjs-plugin-rough@0.2.0"></script>
<script defer src="/assets/scripts/chartjs-plugin-annotation.js"></script>
<!-- <script defer src="/assets/scripts/applyInlineDisqussions.js"></script> -->
<script defer src="/assets/scripts/inline-chartjs.js"></script>

<link href="/assets/css/chardinjs.css" rel="stylesheet">
<script defer src="/assets/scripts/chardinjs.min.js"></script>

<!-- This is entirely for the  datatable.js -->
<link rel="stylesheet" href="/assets/css/bootstrap.css">
<link rel="stylesheet" href="/assets/css/bootstrap-table.min.css"> 
<link rel="stylesheet" href="/assets/css/bootstrap-table-filter-control.min.css">
<link rel="stylesheet" href="/assets/css/datatable.css">

<script defer src="/assets/scripts/bootstrap.min.js"></script>
<script defer src="/assets/scripts/bootstrap-table.min.js"></script>
<script defer src="/assets/scripts/bootstrap-table-filter-control.min.js"></script>
<script defer src="/assets/scripts/moment.min.js"></script>
<script defer type="text/javascript" src="/assets/scripts/datatable.js"></script>

  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          damageboy
          
        </a>
        <ul class="visible-links">
<li class="masthead__menu-item">
              <a href="/">Posts</a>
            </li>
<li class="masthead__menu-item">
              <a href="/talks/">Talks</a>
            </li>
<li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li>
</ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  











<div class="page__hero--overlay" style=" background-image: linear-gradient(rgba(106, 0, 0, 0.6), rgba(106, 0, 0, 0.6)), url('/assets/images/these-go-to-eleven.jpg'), url('/assets/images/these-go-to-eleven.webp');">
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          This Goes to Eleven (Pt. 5/∞)

        
      </h1>
      
        <p class="page__lead">Decimating Array.Sort with AVX2.<br><br> I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics.<br> There’s no reason I should go down alone.
</p>
      
      
        <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  73 minute read

</p>
      
      
      
        <p>
        
          
          <a href="https://github.com/damageboy/vxsort" class="btn btn--light-outline btn--large">GitHub</a>
        
          
          <a href="https://www.nuget.org/packages/VxSort" class="btn btn--light-outline btn--large">Nuget</a>
        
      
    </p>
</div>
  
  
</div>





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/assets/images/atari.svg" alt="damageboy" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">damageboy</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>What did I do this time?</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      
        <li>
          <a href="https://bits.houmus.org" itemprop="url">
            <i class="fas fa-fw fa-link" aria-hidden="true"></i> Website
          </a>
        </li>
      

      
        <li>
          <a href="mailto:dans@houmus.org">
            <meta itemprop="email" content="dans@houmus.org">
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email
          </a>
        </li>
      

      

      
        <li>
          <a href="https://twitter.com/damageboy" itemprop="sameAs" rel="nofollow noopener noreferrer">
            <i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      
        <li>
          <a href="https://stackoverflow.com/users/9172/damageboy" itemprop="sameAs" rel="nofollow noopener noreferrer">
            <i class="fab fa-fw fa-stack-overflow" aria-hidden="true"></i> Stack Overflow
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="This Goes to Eleven (Pt. 5/∞)">
    <meta itemprop="description" content="Decimating Array.Sort with AVX2. I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics. There’s no reason I should go down alone.">
    <meta itemprop="datePublished" content="February 02, 2020">
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
        <p>I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics, and there’s no reason I should go down alone.</p>

<p>Since there’s a lot to go over here, I’ll split it up into a few parts:</p>

<ol>
  <li>In <a href="/2020-01-28/this-goes-to-eleven-pt1">part 1</a>, we start with a refresher on <code class="highlighter-rouge">QuickSort</code> and how it compares to <code class="highlighter-rouge">Array.Sort()</code>.</li>
  <li>In <a href="/2020-01-29/this-goes-to-eleven-pt2">part 2</a>, we go over the basics of vectorized hardware intrinsics, vector types, and go over a handful of vectorized instructions we’ll use in part 3. We still won’t be sorting anything.</li>
  <li>In <a href="/2020-01-30/this-goes-to-eleven-pt3">part 3</a>, we go through the initial code for the vectorized sorting, and start seeing some payoff. We finish agonizing courtesy of the CPU’s branch predictor, throwing a wrench into our attempts.</li>
  <li>In <a href="/2020-02-01/this-goes-to-eleven-pt4">part 4</a>, we go over a handful of optimization approaches that I attempted trying to get the vectorized partition to run faster, seeing what worked and what didn’t.</li>
  <li>In this part, we’ll take a deep dive into how to deal with memory alignment issues.</li>
  <li>In part 6, we’ll take a pause from the vectorized partitioning, to get rid of almost 100% of the remaining scalar code, by implementing small, constant size array sorting with yet more AVX2 vectorization.</li>
  <li>In part 7, We’ll circle back and try to deal with a nasty slowdown left in our vectorized partitioning code</li>
  <li>In part 8, I’ll tell you the sad story of a very twisted optimization I managed to pull off while failing miserably at the same time.</li>
  <li>In part 9, I’ll try some algorithmic improvements to milk those last drops of perf, or at least those that I can think of, from this code.</li>
</ol>

<h2 id="trying-to-squeeze-some-more-vectorized-juice">(Trying) to squeeze some more vectorized juice</h2>

<p>I thought it would be nice to show a bunch of things I ended up trying to improve performance.
I tried to keep most of these experiments in separate implementations, both the ones that yielded positive results and the failures. These can be seen in the original repo under the <a href="https://github.com/damageboy/VxSort/tree/research/VxSortResearch/Unstable/AVX2/Happy">Happy</a> and <a href="https://github.com/damageboy/VxSort/tree/research/VxSortResearch/Unstable/AVX2/Sad">Sad</a> folders.</p>

<p>While some worked, and some didn’t, I think a bunch of these were worth mentioning, so here goes:</p>

<h3 id="aligning-our-expectations">Aligning our expectations</h3>

<center>
<object style="margin: auto; width: 90%" type="image/svg+xml" data="../assets/images/computer-architecture-caches-are-evil-quote.svg"></object>
</center>

<p>This quote, taken from Hennessy and Patterson’s <a href="https://www.elsevier.com/books/computer-architecture/hennessy/978-0-12-811905-1">“Computer Architecture: A Quantitative Approach, 6th Edition”</a>, which is traced to all the way back to the fathers of modern-day computing in 1946 can be taken as a foreboding warning for the pains that are related to anything that deals with the complexity of memory hierarchies.</p>

<p>With modern computer hardware, CPUs <em>might</em> access memory more efficiently when it is naturally aligned: in other words, when the <em>address</em> we use is a multiple of some magical constant. The constant is classically the machine word size, 4/8 bytes on 32/64 bit machines. These constants are related to how the CPU is physically wired and constructed internally. Historically, older processors used to be very limited, either disallowing or severely limiting performance, with non-aligned memory access. To this day, very simple micro-controllers (like the ones you might find in IoT devices, for example) will exhibit such limitations around memory alignment, essentially forcing memory access to conform to multiples of 4/8 bytes. With more modern (read: more expensive) CPUs, these requirements have become increasingly relaxed. Most programmers can simply afford to <em>ignore</em> this issue. The last decade or so worth of modern processors are oblivious to this problem per-se, as long as we access memory within a <strong>single cache-line</strong>, or 64-bytes on almost any modern-day processors.</p>

<p>What is this cache-line? I’m actively fighting my internal inclination, so I <strong>won’t  turn</strong> this post into a detour about computer micro-architecture. Caches have been covered elsewhere ad-nauseam by far more talented writers, that I’ll never do it justice anyway. Instead, I’ll just do the obligatory one-paragraph reminder where we recall that CPUs don’t directly communicate with RAM, as it is dead slow; instead, they read and write from internal, on-die, special/fast memory called caches. Caches contain partial copies of RAM. Caches are faster, smaller, and organized in multiple levels (L1/L2/L3 caches, to name them), where each level is usually larger in size and slightly slower in terms of latency. When the CPU is instructed to access memory, it instead communicates with the cache units, but it never does so in small units. Even when our code is reading a <em>single byte</em>, the CPU will communicate with it’s cache subsystem in a unit-of-work known as a cache-line. In theory, every CPU model may have its own definition of a cache-line, but in practice, the last 15 years of processors seem to have converged on 64-bytes as that golden number.</p>

<p>Now, what happens when, lets say, our read operations end up <strong>crossing</strong> cache-lines?</p>

<center>
<object style="margin: auto; width: 90%" type="image/svg+xml" data="../talks/intrinsics-sorting-2019/cacheline-boundaries.svg"></object>
</center>

<p>As mentioned, the unit-of-work, as far as the CPU is concerned, is a 64-byte cache-line. Therefore, such reads literally cause the CPU to issue <em>two</em> read operations downstream, ultimately directed at the cache units<sup id="fnref:0" role="doc-noteref"><a href="#fn:0" class="footnote">1</a></sup>. These cache-line crossing reads <em>do</em> have a sustained effect on perfromance<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">2</a></sup>. But how often do they occur? Let’s consider this by way of example:<br>
Imagine we are processing a single array sequentially, reading 32-bit integers at a time, or 4-bytes; if for some reason, our starting address is <em>not</em> divisible by 4, cross cache-line reads would occur at a rate of <code class="highlighter-rouge">4/64</code> or <code class="highlighter-rouge">6.25%</code> of reads. Even this paltry rate of cross cache-line reads usually remains in the <em>realm of theory</em> since we have the memory allocator and compiler working in tandem, behind the scenes, to make this go away:</p>

<ul>
  <li>The default allocator <em>always</em> returns memory aligned at least to machine word size on the one hand.</li>
  <li>The compiler/JIT use padding bytes within our classes/structs in-between members, as needed, to ensure that individual members are aligned to 4/8 bytes.</li>
</ul>

<p>So far, I’ve told you why/when you <em>shouldn’t</em> care about alignment. This was my way of both easing you into the topic and helping you feel OK if this is news to you. You really can afford <em>not to think</em> about this without paying any penalty, for the most part. Unfortunately, this <strong>stops</strong> being true for <code class="highlighter-rouge">Vector256&lt;T&gt;</code> sized reads, which are 32 bytes wide (256 bits / 8). And this is <em>doubly not true</em> for our partitioning problem:</p>

<ul>
  <li>The memory handed to us for partitioning/sorting is rarely aligned to 32-bytes, except for dumb luck.<br>
The allocator, allocating an array of 32-bit integers, simply doesn’t care about 32-<strong>byte</strong> alignment.</li>
  <li>Even if it were magically aligned to 32-bytes, it would do us little good; Once a <em>single</em> partition operation is complete, further sub-divisions, inherent with QuickSort, are determined by the (random) new placement of the last pivot we used.<br>
There is no way we will get lucky enough that <em>every partition</em> will be 32-byte aligned.</li>
</ul>

<p>Now that it is clear that we won’t be 32-byte aligned, we finally realize that as we go over the array sequentially (left to right and right to left as we do) issuing <strong>unaligned</strong> 32-byte reads on top of a 64-byte cache-line, we end up reading across cache-lines every <strong>other</strong> read! Or at a rate of 50%! This just escalated from being “…generally not a problem” into a “Houston, we have a problem” very quickly.</p>

<p>You’ve endured through a lot of hand waving so far, let’s try to see if we can get some damning evidence for all of this, by launching <code class="highlighter-rouge">perf</code>, this time tracking the oddly specific <code class="highlighter-rouge">mem_inst_retired.split_loads</code> HW counter:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td>
<td class="rouge-code"><pre><span class="nv">$ COMPlus_PerfMapEnabled</span><span class="o">=</span>1 perf record <span class="nt">-Fmax</span> <span class="nt">-e</span> mem_inst_retired.split_loads <span class="se">\</span>
    ./Example <span class="nt">--type-list</span> DoublePumpJedi <span class="nt">--size-list</span> 100000 <span class="se">\</span>
        <span class="nt">--max-loops</span> 1000 <span class="nt">--no-check</span>
<span class="nv">$ </span>perf report <span class="nt">--stdio</span> <span class="nt">-F</span> overhead,sym | <span class="nb">head</span> <span class="nt">-20</span>

<span class="c"># To display the perf.data header info, please use --header/--header-only options.</span>
<span class="c"># Event count (approx.): 87102613</span>
<span class="c"># Overhead  Symbol</span>
    86.68%  <span class="o">[</span>.] ...DoublePumpJedi::VectorizedPartitionInPlace<span class="o">(</span>int32<span class="k">*</span>,int32<span class="k">*</span><span class="o">)</span>
     5.74%  <span class="o">[</span>.] ...DoublePumpJedi::Sort<span class="o">(</span>int32<span class="k">*</span>,int32<span class="k">*</span>,int32<span class="o">)</span>
     2.99%  <span class="o">[</span>.] __memmove_avx_unaligned_erms
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>We ran the same sort operation <code class="highlighter-rouge">1,000</code> times and got <code class="highlighter-rouge">87,102,613</code> split-loads, with <code class="highlighter-rouge">86.68%</code> attributed to our partitioning function. This means <code class="highlighter-rouge">(87102613 * 0.8668) / 1000</code> or <code class="highlighter-rouge">75,500</code> split-loads <em>per sort</em> of <code class="highlighter-rouge">100,000</code> elements. To seal the deal, we need to figure out how many vector loads per sort we are performing in the first place; Luckily I can generate an answer quickly: I have statistics collection code embedded in my code, so I can issue this command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td>
<td class="rouge-code"><pre><span class="nv">$ </span>./Example <span class="nt">--type-list</span> DoublePumpJedi <span class="se">\</span>
      <span class="nt">--size-list</span> 100000 <span class="nt">--max-loops</span> 10000 <span class="se">\</span>
      <span class="nt">--no-check</span> <span class="nt">--stats-file</span> jedi-100k-stats.json
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>And in return I get this beutiful thing back:</p>

<table style="margin-bottom: 0em" class="notice--info">
<tr>
<td style="border: none; padding-top: 0; padding-bottom: 0; vertical-align: top"><span class="uk-label">Note</span></td>
<td style="border: none; padding-top: 0; padding-bottom: 0">
<div>
        <p>These numbers are vastly different than the ones we last saw in the end of the 3<sup>rd</sup> post, for example. There is a good reason for this: We’ve spent the previous post tweaking the code in a few considerable ways:</p>
        <ul>
          <li>Changing the cut-off point for vectorized sorting from 16 ⮞ 40, there-by reducing the amount of vectorized partitions we’re performing in the first place.</li>
          <li>Changing the permutation entry loading code to read 8-byte values from memroy, rather than full 32-byte <code class="highlighter-rouge">Vector256&lt;int&gt;</code> entries,
cutting the number of <code class="highlighter-rouge">Vector256&lt;int&gt;</code> loads by half.</li>
        </ul>
      </div>
</td>
</tr>
</table>

<div>
<!-- <button class="helpbutton" data-toggle="chardinjs" onclick="$('body').chardinJs('start')"><object style="pointer-events: none;" type="image/svg+xml" data="/assets/images/help.svg"></object></button> -->

<table class="table datatable" data-json="../_posts/jedi-stats.json" data-id-field="name" data-pagination="false" data-intro="Each row in this table contains statistics collected &amp; averaged out of thousands of runs with random data" data-position="left" data-show-pagination-switch="false">
  <thead data-intro="The header can be used to sort/filter by clicking" data-position="right">
    <tr>
        <th data-field="MethodName" data-sortable="true" data-filter-control="select">
          <span data-intro="The name of the benchmarked method" data-position="top">Method<br>Name</span>
        </th>
        <th data-field="ProblemSize" data-sortable="true" data-value-type="int" data-filter-control="select">
            <div data-intro="The size of the sorting problem being benchmarked (# of integers)" data-position="bottom" class="rotated-header-container">
            <div class="rotated-header">Size</div>
            </div>
        </th>
        <th data-field="MaxDepthScaledDataTable" data-sortable="true" data-value-type="inline-bar-horizontal">
            <div data-intro="The maximal depth of recursion reached while sorting" data-position="top" class="rotated-header-container">
              <div class="rotated-header">Max</div>
              <div class="rotated-header">Depth</div>
            </div>
        </th>
        <th data-field="NumPartitionOperationsScaledDataTable" data-sortable="true" data-value-type="inline-bar-horizontal">
            <div data-intro="# of partitioning operations per sort" data-position="bottom" class="rotated-header-container">
              <div class="rotated-header">Part</div>
              <div class="rotated-header">itions</div>
            </div>
        </th>
        <th data-field="NumVectorizedLoadsScaledDataTable" data-sortable="true" data-value-type="inline-bar-horizontal">
            <div data-intro="# of vectorized load operations" data-position="top" class="rotated-header-container">
              <div class="rotated-header">Vector</div>
              <div class="rotated-header">Loads</div>
            </div>
        </th>
        <th data-field="NumVectorizedStoresScaledDataTable" data-sortable="true" data-value-type="inline-bar-horizontal">
            <div data-intro="# of vectorized store operations" data-position="bottom" class="rotated-header-container">
              <div class="rotated-header">Vector</div>
              <div class="rotated-header">Stores</div>
            </div>
        </th>
        <th data-field="NumPermutationsScaledDataTable" data-sortable="true" data-value-type="inline-bar-horizontal">
            <div data-intro="# of vectorized permutation operations" data-position="top" class="rotated-header-container">
              <div class="rotated-header">Vector</div>
              <div class="rotated-header">Permutes</div>
            </div>
        </th>
        <th data-field="AverageSmallSortSizeScaledDataTable" data-sortable="true" data-value-type="inline-bar-horizontal">
            <div data-intro="For hybrid sorting, the average size that each small sort operation was called with (e.g. InsertionSort)" data-position="bottom" class="rotated-header-container">
              <div class="rotated-header">Small</div>
              <div class="rotated-header">Sort</div>
              <div class="rotated-header">Size</div>
            </div>
        </th>
        <th data-field="NumScalarComparesScaledDataTable" data-sortable="true" data-value-type="inline-bar-horizontal">
            <div data-intro="How many branches were executed in each sort operation that were based on the unsorted array elements" data-position="top" class="rotated-header-container">
              <div class="rotated-header">Data</div>
              <div class="rotated-header">Based</div>
              <div class="rotated-header">Branches</div>
            </div>
        </th>
        <th data-field="PercentSmallSortCompares" data-sortable="true" data-value-type="float2-percentage">
            <div data-intro="What percent of&lt;/br&gt;⬅&lt;br/&gt;branches happenned as part of small-sorts" data-position="bottom" class="rotated-header-container">
              <div class="rotated-header">Small</div>
              <div class="rotated-header">Sort</div>
              <div class="rotated-header">Branches</div>
            </div>
        </th>
    </tr>
  </thead>
</table>
</div>

<p>In total, we perform <code class="highlighter-rouge">173,597</code> vector loads per sort operation of <code class="highlighter-rouge">100,000</code> elements in <code class="highlighter-rouge">4,194</code> partitioning calls. Assuming our array is aligned to 4-bytes to begin with (which C#’s allocator does very reliably), every partitioning call has a <code class="highlighter-rouge">4/32</code> or <code class="highlighter-rouge">12.5%</code> of ending up being 32-byte aligned: In other words <code class="highlighter-rouge">21,700</code> of the total vector reads should be aligned by sheer chance, which leaves <code class="highlighter-rouge">173597-21700</code> or <code class="highlighter-rouge">151,898</code> that should be <em>unaligned</em>, of which, I claim that that ½ would cause split-loads: <code class="highlighter-rouge">50%</code> of <code class="highlighter-rouge">151,898</code> is <code class="highlighter-rouge">75,949</code> while we measured <code class="highlighter-rouge">75,500</code> with <code class="highlighter-rouge">perf</code>! I don’t know how your normal day goes about, but in mine, reality and my hallucinations rarely go hand-in-hand like this.</p>

<p>Fine, we now <strong>know</strong> we have a problem. The first step was acknowledging/accepting reality: Our code does indeed generate a lot of split memory operations. Let’s consider our memory access patterns when reading/writing with respect to alignment, and see if we can do something about it:</p>

<ul>
  <li>For writing, we’re all over the place: we always advance the write pointers according to how the data was partitioned, e.g. it is completely data-dependent, and there is little we can say about our write addresses. In addition, as it happens, Intel CPUs, as almost all other modern CPUs, employ another common trick in the form of <a href="https://en.wikipedia.org/wiki/Write_combining">store buffers, or write-combining buffers (WCBs)</a>. I’ll refrain from describing them here, but the bottom line is we both can’t/don’t need to care about the writing side of our algorithm.</li>
  <li>For reading, the situation is entirely different: We <em>always</em> advance the read pointers by 8 elements (32-bytes) on the one hand, and we even have a special intrinsic: <code class="highlighter-rouge">Avx.LoadAlignedVector256() / VMOVDQA</code><sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">3</a></sup> that helps us ensure that our reading is properly aligned to 32-bytes.</li>
</ul>

<h4 id="aligning-to-cpu-cache-lines-1">Aligning to CPU Cache-lines: <img class="emoji" title=":+1:" alt=":+1:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png" height="20" width="20">
</h4>

<p>With this lengthy introduction out of the way, it’s time we do something about these cross-cache line reads. Initially, I got “something” working quickly: remember that we needed to deal with the <em>remainder</em> of the array, when we had less than 8-elements, anyway. In the original code at the end of the 3<sup>rd</sup> post, we did so right after our vectorized loop. If we move that scalar code from the end of the function to its beginning while also modifying it to perform scalar partitioning until both <code class="highlighter-rouge">readLeft</code>/<code class="highlighter-rouge">readRight</code> pointers are aligned to 32 bytes, our work is complete. There is a slight wrinkle in this otherwise simple approach:</p>

<ul>
  <li>Previously, we had anywhere between <code class="highlighter-rouge">0-7</code> elements left as a remainder for scalar partitioning per partition call.
    <ul>
      <li>
<code class="highlighter-rouge">3.5</code> elements on average.</li>
    </ul>
  </li>
  <li>Aligning from the edges of our partition with scalar code means we will now have <code class="highlighter-rouge">0-7</code> elements per-side…
    <ul>
      <li>So <code class="highlighter-rouge">3.5 x 2 == 7</code> elements on average.</li>
    </ul>
  </li>
</ul>

<p>In other words, doing this sort of inwards pre-alignment optimization is not a clean win: We end up with more scalar work than before on the one hand (which is unfortunate), but on the other hand, we can change the vector loading code to use <code class="highlighter-rouge">Avx.LoadAlignedVector256()</code> and <em>know for sure</em> that we will no longer be causing the CPU to issue a single cross cache-line read (The latter being the performance boost).<br>
It’s understandable if while reading this, your gut reaction is thinking that adding 3.5 scalar operations doesn’t sound like much of a trade-off, but we have to consider that:</p>

<ul>
  <li>Each scalar comparison comes with a likely branch misprediction, as discussed before, so it has a higher cost than what you might be initially pricing in.</li>
  <li>More importantly: we can’t forget that this is a recursive function, with ever <em>decreasing</em> partition sizes. If you go back to the initial stats we collected in previous posts, you’ll be quickly reminded that we partition upwards of 340k times for 1 million element arrays, so this scalar work both piles up, and represents a larger portion of our workload as the partition sizes decrease…</li>
</ul>

<p>I won’t bother showing the entire code listing for <a href="https://github.com/damageboy/VxSort/blob/research/VxSortResearch/Unstable/AVX2/Happy/B5_1_DoublePumpAligned.cs"><code class="highlighter-rouge">B5_1_DoublePumpAligned.cs</code></a>, but I will show the rewritten scalar partition block, which is now tasked with aligning our pointers before we go full vectorized partitioning. Originally it was right after the double-pumped loop and looked like this:</p>

<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td>
<td class="rouge-code"><pre>    <span class="c1">// ...</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">readLeft</span> <span class="p">&lt;</span> <span class="n">readRight</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">var</span> <span class="n">v</span> <span class="p">=</span> <span class="p">*</span><span class="n">readLeft</span><span class="p">++;</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">v</span> <span class="p">&lt;=</span> <span class="n">pivot</span><span class="p">)</span> <span class="p">{</span>
            <span class="p">*</span><span class="n">tmpLeft</span><span class="p">++</span> <span class="p">=</span> <span class="n">v</span><span class="p">;</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="p">*--</span><span class="n">tmpRight</span> <span class="p">=</span> <span class="n">v</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>The aligned variant, with the alignment code now at the top of the function, looks like this:</p>

<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre></td>
<td class="rouge-code"><pre>    <span class="k">const</span> <span class="kt">ulong</span> <span class="n">ALIGN</span> <span class="p">=</span> <span class="m">32</span><span class="p">;</span>
    <span class="k">const</span> <span class="kt">ulong</span> <span class="n">ALIGN_MASK</span> <span class="p">=</span> <span class="n">ALIGN</span> <span class="p">-</span> <span class="m">1</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(((</span><span class="kt">ulong</span><span class="p">)</span> <span class="n">readLeft</span> <span class="p">&amp;</span> <span class="n">ALIGN_MASK</span><span class="p">)</span> <span class="p">!=</span> <span class="m">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">var</span> <span class="n">nextAlign</span> <span class="p">=</span> <span class="p">(</span><span class="kt">int</span> <span class="p">*)</span> <span class="p">(((</span><span class="kt">ulong</span><span class="p">)</span> <span class="n">readLeft</span> <span class="p">+</span> <span class="n">ALIGN</span><span class="p">)</span> <span class="p">&amp;</span> <span class="p">~</span><span class="n">ALIGN_MASK</span><span class="p">);</span>
        <span class="k">while</span> <span class="p">(</span><span class="n">readLeft</span> <span class="p">&lt;</span> <span class="n">nextAlign</span><span class="p">)</span> <span class="p">{</span>
            <span class="kt">var</span> <span class="n">v</span> <span class="p">=</span> <span class="p">*</span><span class="n">readLeft</span><span class="p">++;</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">v</span> <span class="p">&lt;=</span> <span class="n">pivot</span><span class="p">)</span> <span class="p">{</span>
                <span class="p">*</span><span class="n">tmpLeft</span><span class="p">++</span> <span class="p">=</span> <span class="n">v</span><span class="p">;</span>
            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                <span class="p">*--</span><span class="n">tmpRight</span> <span class="p">=</span> <span class="n">v</span><span class="p">;</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="n">Debug</span><span class="p">.</span><span class="nf">Assert</span><span class="p">(((</span><span class="kt">ulong</span><span class="p">)</span> <span class="n">readLeft</span> <span class="p">&amp;</span> <span class="n">ALIGN_MASK</span><span class="p">)</span> <span class="p">==</span> <span class="m">0</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(((</span><span class="kt">ulong</span><span class="p">)</span> <span class="n">readRight</span> <span class="p">&amp;</span> <span class="n">ALIGN_MASK</span><span class="p">)</span> <span class="p">!=</span> <span class="m">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">var</span> <span class="n">nextAlign</span> <span class="p">=</span> <span class="p">(</span><span class="kt">int</span> <span class="p">*)</span> <span class="p">((</span><span class="kt">ulong</span><span class="p">)</span> <span class="n">readRight</span> <span class="p">&amp;</span> <span class="p">~</span><span class="n">ALIGN_MASK</span><span class="p">);</span>
        <span class="k">while</span> <span class="p">(</span><span class="n">readRight</span> <span class="p">&gt;</span> <span class="n">nextAlign</span><span class="p">)</span> <span class="p">{</span>
            <span class="kt">var</span> <span class="n">v</span> <span class="p">=</span> <span class="p">*--</span><span class="n">readRight</span><span class="p">;</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">v</span> <span class="p">&lt;=</span> <span class="n">pivot</span><span class="p">)</span> <span class="p">{</span>
                <span class="p">*</span><span class="n">tmpLeft</span><span class="p">++</span> <span class="p">=</span> <span class="n">v</span><span class="p">;</span>
            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                <span class="p">*--</span><span class="n">tmpRight</span> <span class="p">=</span> <span class="n">v</span><span class="p">;</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="n">Debug</span><span class="p">.</span><span class="nf">Assert</span><span class="p">(((</span><span class="kt">ulong</span><span class="p">)</span> <span class="n">readRight</span> <span class="p">&amp;</span> <span class="n">ALIGN_MASK</span><span class="p">)</span> <span class="p">==</span> <span class="m">0</span><span class="p">);</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>What it does now is check when alignment is necessary, then proceeds to align while also partitioning each side into the temporary memory.</p>

<p>Where do we end up performance-wise with this optimization?</p>

<div>
  <div class="stickemup">

<ul class="uk-tab" data-uk-switcher="{connect:'#50d405d8-6a9a-4b68-9b7f-20445b335308'}">

	<li class="uk-active"><a href="#"><i class="glyphicon glyphicon-stats"></i> Scaling</a></li>

	<li><a href="#"><i class="glyphicon glyphicon-stats"></i> Time/N</a></li>

	<li><a href="#"><i class="glyphicon glyphicon-list-alt"></i> Benchmarks</a></li>

	<li><a href="#"><i class="glyphicon glyphicon-info-sign"></i> Setup</a></li>

</ul>

<ul id="50d405d8-6a9a-4b68-9b7f-20445b335308" class="uk-switcher uk-margin">

	<li>
<div>
<button class="helpbutton" data-toggle="chardinjs" onclick="$('body').chardinJs('start')"><object style="pointer-events: none;" type="image/svg+xml" data="/assets/images/help.svg"></object></button>
<div data-intro="Size of the sorting problem, 10..10,000,000 in powers of 10" data-position="bottom">
<div data-intro="Performance scale: Array.Sort (solid gray) is always 100%, and the other methods are scaled relative to it" data-position="left">
<div data-intro="Click legend items to show/hide series" data-position="right">
<div class="benchmark-chart-container">
<canvas data-chart="line">
N,100,1K,10K,100K,1M,10M
Jedi,         1   , 1   , 1  , 1   , 1    , 1
Aligned, 1.082653616,    1.091733385,    0.958578753,    0.959159569,    0.964604818,    0.980102965
<!-- 
{ 
 "data" : {
  "datasets" : [
  { 
    "backgroundColor": "rgba(66,66,66,0.35)",
    "rough": { "fillStyle": "hachure", "hachureAngle": -30, "hachureGap": 9, "fillWeight": 0.3}
  },
  { 
    "backgroundColor": "rgba(33,220,33,.9)",
    "rough": { "fillStyle": "hachure", "hachureAngle": 60, "hachureGap": 3}
  }  
  ]
 },
 "options": {
    "title": { "text": "AVX2 Aligned Sorting - Scaled to Jedi", "display": true },
    "scales": { 
      "yAxes": [{
       "ticks": {
         "fontFamily": "Indie Flower",
         "min": 0.90, 
         "callback": "ticksPercent"
        },
        "scaleLabel": {
          "labelString": "Scaling (%)",
          "display": true
        }
      }]
    }
 },
 "defaultOptions": {"scales":{"xAxes":[{"scaleLabel":{"display":"true,","labelString":"N (elements)","fontFamily":"Indie Flower"},"ticks":{"fontFamily":"Indie Flower"}}]},"legend":{"display":true,"position":"bottom","labels":{"fontFamily":"Indie Flower","fontSize":14}},"title":{"position":"top","fontFamily":"Indie Flower","fontSize":16}}
}
--> </canvas>

</div>
</div>
</div>
</div>
</div>

</li>

	<li>
<div>
<button class="helpbutton" data-toggle="chardinjs" onclick="$('body').chardinJs('start')"><object style="pointer-events: none;" type="image/svg+xml" data="/assets/images/help.svg"></object></button>
<div data-intro="Size of the sorting problem, 10..10,000,000 in powers of 10" data-position="bottom">
<div data-intro="Time in nanoseconds spent sorting per element. Array.Sort (solid gray) is the baseline, again" data-position="left">
<div data-intro="Click legend items to show/hide series" data-position="right">
<div class="benchmark-chart-container">
<canvas data-chart="line">
N,100,1K,10K,100K,1M,10M
Jedi, 18.3938  ,20.7342  ,24.6347  ,26.9067  ,23.9922  ,25.5122
Aligned, 19.9128, 22.6363, 23.6143, 25.8078, 23.143, 25.0046
<!-- 
{ 
 "data" : {
  "datasets" : [
  { 
    "backgroundColor": "rgba(66,66,66,0.35)",
    "rough": { "fillStyle": "hachure", "hachureAngle": -30, "hachureGap": 9, "fillWeight": 0.3}
  },
  { 
    "backgroundColor": "rgba(33,220,33,.9)",
    "rough": { "fillStyle": "hachure", "hachureAngle": 60, "hachureGap": 3}
  }
  ]
 },
 "options": {
    "title": { "text": "AVX2 Jedi Sorting + Aligned - log(Time/N)", "display": true },
    "scales": { 
      "yAxes": [{ 
        "type": "logarithmic",
        "ticks": {
          "min": 15,
          "max": 28,
          "callback": "ticksNumStandaard",
          "fontFamily": "Indie Flower"          
        },
        "scaleLabel": {
          "labelString": "Time/N (ns)",
          "fontFamily": "Indie Flower",
          "display": true
        }
      }]
    }
 },
 "defaultOptions": {"scales":{"xAxes":[{"scaleLabel":{"display":"true,","labelString":"N (elements)","fontFamily":"Indie Flower"},"ticks":{"fontFamily":"Indie Flower"}}]},"legend":{"display":true,"position":"bottom","labels":{"fontFamily":"Indie Flower","fontSize":14}},"title":{"position":"top","fontFamily":"Indie Flower","fontSize":16}}
}
--> </canvas>

</div>
</div>
</div>
</div>
</div>
</li>

	<li>
<div>
<button class="helpbutton" data-toggle="chardinjs" onclick="$('body').chardinJs('start')"><object style="pointer-events: none;" type="image/svg+xml" data="/assets/images/help.svg"></object></button>
<table class="table datatable" data-json="../_posts/Bench.BlogPt5_1_Int32_-report.datatable.json" data-id-field="name" data-pagination="false" data-page-list="[9, 18]" data-intro="Each row in this table represents a benchmark result" data-position="left" data-show-pagination-switch="false">
  <thead data-intro="The header can be used to sort/filter by clicking" data-position="right">
    <tr>
        <th data-field="TargetMethodColumn.Method" data-sortable="true" data-filter-control="select">
          <span data-intro="The name of the benchmarked method" data-position="top">
            Method<br>Name
          </span>
        </th>
        <th data-field="N" data-sortable="true" data-value-type="int" data-filter-control="select">
            <span data-intro="The size of the sorting problem being benchmarked (# of integers)" data-position="top">
            Problem<br>Size
            </span>
        </th>
        <th data-field="TimePerNDataTable" data-sortable="true" data-value-type="float2-interval-muted">
            <span data-intro="Time in nanoseconds spent sorting each element in the array (with confidence intervals in parenthesis)" data-position="top">
              Time /<br>Element (ns)
            </span>
        </th>
        <th data-field="RatioDataTable" data-sortable="true" data-value-type="inline-bar-horizontal-percentage">
            <span data-intro="Each result is scaled to its baseline (Array.Sort in this case)" data-position="top">
                  Scaling
            </span>
        </th>
        <th data-field="Measurements" data-sortable="true" data-value-type="inline-bar-vertical">
            <span data-intro="Raw benchmark results visualize how stable the result it. Longest/Shortest runs marked with &lt;span style='color: red'&gt;Red&lt;/span&gt;/&lt;span style='color: green'&gt;Green&lt;/span&gt;" data-position="top">Measurements</span>
        </th>
    </tr>
  </thead>
</table>
</div>

</li>

	<li>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td>
<td class="rouge-code"><pre><span class="nv">BenchmarkDotNet</span><span class="o">=</span>v0.12.0, <span class="nv">OS</span><span class="o">=</span>clear-linux-os 32120
Intel Core i7-7700HQ CPU 2.80GHz <span class="o">(</span>Kaby Lake<span class="o">)</span>, 1 CPU, 4 logical and 4 physical cores
.NET Core <span class="nv">SDK</span><span class="o">=</span>3.1.100
  <span class="o">[</span>Host]     : .NET Core 3.1.0 <span class="o">(</span>CoreCLR 4.700.19.56402, CoreFX 4.700.19.56404<span class="o">)</span>, X64 RyuJIT
  Job-DEARTS : .NET Core 3.1.0 <span class="o">(</span>CoreCLR 4.700.19.56402, CoreFX 4.700.19.56404<span class="o">)</span>, X64 RyuJIT

<span class="nv">InvocationCount</span><span class="o">=</span>3  <span class="nv">IterationCount</span><span class="o">=</span>15  <span class="nv">LaunchCount</span><span class="o">=</span>2
<span class="nv">UnrollFactor</span><span class="o">=</span>1  <span class="nv">WarmupCount</span><span class="o">=</span>10

<span class="nv">$ </span><span class="nb">grep</span> <span class="s1">'stepping\|model\|microcode'</span> /proc/cpuinfo | <span class="nb">head</span> <span class="nt">-4</span>
model           : 158
model name      : Intel<span class="o">(</span>R<span class="o">)</span> Core<span class="o">(</span>TM<span class="o">)</span> i7-7700HQ CPU @ 2.80GHz
stepping        : 9
microcode       : 0xb4
</pre></td>
</tr></tbody></table></code></pre></div></div>

</li>

</ul>

</div>

  <p>The whole attempt ends up as a mediocre improvement, so it would seem:</p>

  <ul>
    <li>We’re are seeing a speedup/improvement, in the high counts.</li>
    <li>We seem to be slowing down due to the higher scalar operation count, in the low problem sizes.</li>
  </ul>

  <p>It’s kind of a mixed bag, and perhaps slightly unimpressive at first glance. However, when we stop to remember that we somehow managed both to speed up the function while doubling the amount of scalar work done, the interpretation of the results becomes more nuanced: The pure benefit from alignment itself is larger than what the results are showing right now since it’s being masked, to some extent, by the extra scalar work we tacked on. If only there was a way we could skip that scalar work all together… If only there was a way… If only…</p>
</div>

<h3 id="re-partitioning-overlapping-regions-1-1">(Re-)Partitioning overlapping regions: <img class="emoji" title=":+1:" alt=":+1:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png" height="20" width="20"> <img class="emoji" title=":+1:" alt=":+1:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png" height="20" width="20">
</h3>

<p>Next up is a different optimization approach to the same problem, and a natural progression from the last one. At the risk of sounding pompous, I think I <em>might</em> have found something here that no-one has done before in the context of partitioning<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">4</a></sup>: The basic idea here is we get rid of all (ok, ok, <em>almost all</em>) scalar partitioning in our vectorized code path. If we can partition and align the edges of the segment we are about to process with vectorized code, we would be reducing the total number instructions executed. At the same time, we would be retaining more of the speed-up that was lost with the alignment optimization above. This would have a double-whammy compounded effect. But how?</p>

<object style="margin: auto" type="image/svg+xml" data="../talks/intrinsics-sorting-2019/overlap-partition-with-hint.svg"></object>

<p>We could go about it the other way around! Instead of aligning <em>inwards</em> in each respective direction, we could align <strong><em>outwards</em></strong> and enlarge the partitioned segment to include a few more (up to 7) elements on the outer rims of each partition and <u>re-partition</u> them using the new pivot we’ve just selected. If this works, we end up doing both 100% aligned reads and eliminating all scalar work in one optimization! This might <em>sound simple</em> and <strong>safe</strong>, but this is the sort of humbling experience that QuickSort is quick at dispensing (sorry, I had to…) at people trying to nudge it in the wrong way. At some point, I was finally able to screw my own head on properly with respect to this re-partitioning attempt and figure out what precisely are the critical constraints we must respect for this to work.</p>

<table style="margin-bottom: 0em" class="notice--info">
<tr>
<td style="border: none; padding-top: 0; padding-bottom: 0; vertical-align: top"><span class="uk-label">Note</span></td>
<td style="border: none; padding-top: 0; padding-bottom: 0">
<div>
        <p>This is a slightly awkward optimization when you consider that I’m suggesting we should <strong>partition more data</strong> in order to <em>speed up</em> our code. This sounds bonkers, unless we dig deep within for some mechanical empathy: not all work is equal in the eyes of the CPU. When we are executing scalar partitioning on <em>n</em> elements, we are really telling the CPU to execute <em>n</em> branches, comparisons, and memory accesses, which are completely data-dependent. The CPU “hates” this sort of work. It has to guess what happens next, and will do so no better than flipping a coin, or 50%, for truly random data. What’s worse, as mentioned before, whenever the CPU mispredicts, there’s a price to pay in the form of a full pipeline flush which roughly costs us 14-15 cycles on a modern CPU. Paying this <strong>once</strong>, is roughly equivalent to partitioning 2 x 8 element vectors with our vectorized partition block! This is the reason that doing “more” might be faster.</p>
      </div>
</td>
</tr>
</table>

<p>Back to the constraints. There’s one thing we can <strong>never</strong> do: move a pivot that was previously partitioned. I (now) call them “buried pivots” (since they’re in their final resting place, get it?); Everyone knows, you don’t move around dead bodies, that’s always the first bad thing that happens in a horror movie. There’s our motivation: not being the stupid person who dies first. That’s about it. It sounds simple, but it requires some more serious explanation: When a previous partition operation is complete, the pivot used during that operation is moved to its final resting place. It’s new position is used to subdivide the array, and effectively stored throughout numerous call stacks of our recursive function. There’s a baked-in assumption here that all data left/right of that buried pivot is smaller/larger than it. And that assumption must <strong>never</strong> be broken. If we intend to <strong>re-partition</strong> data to the left and right of a given partition, as part of this overlapping alignment effort, we need to consider that this extra data might already contain buried pivots, and we can not, under any circumstances ever move them again.<br>
In short: Buried pivots stay buried where we left them, or bad things happen.</p>

<p>When we call our partitioning operation, we have to consider what initially looks like an asymmetry of the left and right edges of our to-be-partitioned segment:</p>

<ul>
  <li>For the left side:
    <ul>
      <li>There might not be additional room on the left with extra data to read from.
        <ul>
          <li>We are too close to the edge of the array on the left side!<br>
This happens for all partitions starting at the left-edge of the entire array.</li>
        </ul>
      </li>
      <li>We always partition first left, then right of any buried pivot, we know for a fact that all elements left of “our” partition at any given moment are sorted. e.g. they are all buried pivots, and we can’t re-order them.</li>
      <li>
<em>Important:</em> We also know that each of those values is smaller than or equal to whatever pivot value we <em>will select</em> for the current partitioning operation.</li>
    </ul>
  </li>
  <li>For the right side, it is almost the same set of constraints:
    <ul>
      <li>There might not be additional room on the right with extra data to read from.
        <ul>
          <li>We are too close to the edge of the array on the right side!<br>
This happens for all partitions ending on the right-edge of the entire array.</li>
        </ul>
      </li>
      <li>The immediate value to our right side is a buried pivot, and all other values to its right are larger-than-or-equal to it.</li>
      <li>There might be additional pivots immediately to our right as well.</li>
      <li>
<em>Important:</em> We also know that each of those values is larger-then-or-equal to whatever pivot value we <em>will select</em> for the current partitioning operation.</li>
    </ul>
  </li>
</ul>

<p>All this information is hard to integrate at first, but what it boils down to is that whenever we load up the left overlapping vector, there are anywhere between 1-7 elements we are <strong>not</strong> allowed to reorder on the <em>left side</em>, and when we load the right overlapping vector, there are, again, anywhere between 1-7 elements we are <strong>not</strong> allowed to re-order on <em>that right side</em>. That’s the challenge; the good news is that all those overlapping elements are also guaranteed to also be smaller/larger than whatever pivot we end up selecting from out original (sans overlap) partition. This knowledge gives us the edge we need: We know in advance that the extra elements will generate predictable comparison results compared to <em>any</em> pivot <em>within</em> our partition.</p>

<p>What we need are permutation entries that are <strong><em>stable</em></strong>. I’m coining this phrase freely as I’m going along:<br>
Stable partitioning means that the partitioning operation <strong>must not</strong> <em>reorder</em> values that need to go on the left amongst themselves (we keep their internal ordering amongst themselves). Likewise, it <strong>must not</strong> reorder the values that go on the right amongst themselves. If we manage to do this, we’re in the clear: The combination of stable permutation and predictable comparison results means that the overlapping elements will stay put while other elements will be partitioned properly on both edges of our overlapping partition. After this weird permutation, we just need to forget we ever read those extra elements, and the whole thing just… works? … yes!</p>

<p>Let’s start with cementing this idea of what stable partitioning is: Up to this point, there was no such requirement, and the initial partition tables I generated failed to satisfy this requirement.
Here’s a simple example for stable/unstable permutation entries, let’s imagine we partition the following values around a pivot value of 500:</p>

<table>
  <thead>
    <tr>
      <th>Bit</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
<code class="highlighter-rouge">Vector256&lt;T&gt;</code> Value</td>
      <td>99</td>
      <td>100</td>
      <td>666</td>
      <td>101</td>
      <td>102</td>
      <td>777</td>
      <td>888</td>
      <td>999</td>
    </tr>
    <tr>
      <td>Mask</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Unstable Permutation</td>
      <td>0</td>
      <td>1</td>
      <td><strong>7</strong></td>
      <td>2</td>
      <td>3</td>
      <td><strong>6</strong></td>
      <td><strong>5</strong></td>
      <td><strong>4</strong></td>
    </tr>
    <tr>
      <td>Unstable Result</td>
      <td>99</td>
      <td>100</td>
      <td>101</td>
      <td>102</td>
      <td><strong>999</strong></td>
      <td><strong>888</strong></td>
      <td><strong>777</strong></td>
      <td><strong>666</strong></td>
    </tr>
    <tr>
      <td>Stable Permutation</td>
      <td>0</td>
      <td>1</td>
      <td>4</td>
      <td>2</td>
      <td>3</td>
      <td>5</td>
      <td>6</td>
      <td>7</td>
    </tr>
    <tr>
      <td>Stable Result</td>
      <td>99</td>
      <td>100</td>
      <td>101</td>
      <td>102</td>
      <td>666</td>
      <td>777</td>
      <td>888</td>
      <td>999</td>
    </tr>
  </tbody>
</table>

<p>In the above example, the unstable permutation is a perfectly <em><u>valid</u></em> permutation for general case partitioning. It successfully partitions the sample vector around the pivot value of 500, but the 4 elements marked in bold are re-ordered with respect to each other when compared to the original array. In the stable permutation entry, the internal ordering amongst the partitioned groups is <em>preserved</em>.</p>

<p>Armed with new, stable permutation entries, We can proceed with this overlapping re-partitioning hack: The idea is to find the optimal alignment point on the left and on the right (assuming one is available, e.g. there is enough room on that side), read that data with the <code class="highlighter-rouge">LoadVectorAligned256</code> intrinsic, and partition it into the temporary area. The final twist: We need to keep tabs on how many elements <em>do not belong</em> to this partition (e.g. originate from our overlap gymnastics), and remember not to copy them back into our partition at the end of the function, relying on our stable partitioning to keep them grouped at the edges of the temporary buffer we’re copying from… To my amazement, that was kind of it. It just works! (I’ve conveniently ignored a small edge-case here in words, but not in the code :).</p>

<p>The end result is super delicate. If you feel you’ve got it, skip this paragraph, but if you need an alternative view on how this works, here it is: I’ve just described how to partition the initial 2x8 elements (8 on each side); out of those initial 8, We <em>always</em> have a subset that must <strong>never</strong> be reordered (the overlap), and a subset we need to re-order, as is normal, with respect to some pivot. We know that whatever <em>possible</em> pivot value <em>might</em> be selected from our internal partition, it will always be larger/smaller than the elements in the overlapping areas. Knowing that, we can rely on having stable permutation entries that <strong>do not</strong> reorder those extra elements. In the end, we read extra elements, feed them through our partitioning machine, but ignore the extra overlapping elements and avoid <em>all</em> scalar partitioning thanks to this scheme.</p>

<p>In the end, we literally get to eat our cake and keep it whole: For the 99% case we <strong>kill</strong> scalar partitioning all-together, doing <em>zero</em> scalar work, at the same time aligning everything to <code class="highlighter-rouge">Vector256&lt;T&gt;</code> size and being nice to our processor. Just to make this victory a tiny touch sweeter, even the <em>initial</em> 2x8 partially overlapping vectors are read using aligned reads!
I named this approach “overligned” (overlap + align) in my code-base; it is available in full in <a href="https://github.com/damageboy/VxSort/blob/research/VxSortResearch/Unstable/AVX2/Happy/B5_2_DoublePumpOverlined.cs"><code class="highlighter-rouge">B5_2_DoublePumpOverlined.cs</code></a>. It implements this overlapping alignment approach, with some extra small points for consideration:</p>

<ul>
  <li>When it is <strong>impossible</strong> to align outwards, we fall back to the alignment mechanic introduced in the previous section.<br>
This is uncommon: Going back to the statistical data we collected about random-data sorting in the 3<sup>rd</sup> post, we anticipate a recursion depth of around 40 when sorting 1M elements and ~340K partitioning calls. We will have <em>at least</em> 40x2 (for both sides) such cases where we align inwards for that 1M case, as an example. This is small change compared to the <code class="highlighter-rouge">340K - 80</code> calls we can optimize with outward alignment, but it does mean we have to keep that old code lying around.</li>
  <li>Once we calculate for a given partition how much alignment is required on each side, we can cache that calculation recursively for the entire depth of the recursive call stack: This again reduces the overhead we are paying for this alignment strategy.
In the code you’ll see I’m squishing two 32-bit integers into a 64-bit value I call <code class="highlighter-rouge">alignHint</code> and I keep reusing one half of 64-bit value without recalculating the alignment <em>amount</em>; If we’ve made it this far, let’s shave a few more cycles off while we’re here.</li>
</ul>

<p>There’s another small optimization I tacked on to this version, which I’ll discuss immediately after providing the results:</p>

<div>
  <div class="stickemup">

<ul class="uk-tab" data-uk-switcher="{connect:'#3d6bdb20-d0b7-4c05-ae7d-d6aa78662bad'}">

	<li class="uk-active"><a href="#"><i class="glyphicon glyphicon-stats"></i> Scaling</a></li>

	<li><a href="#"><i class="glyphicon glyphicon-stats"></i> Time/N</a></li>

	<li><a href="#"><i class="glyphicon glyphicon-list-alt"></i> Benchmarks</a></li>

	<li><a href="#"><i class="glyphicon glyphicon-info-sign"></i> Setup</a></li>

</ul>

<ul id="3d6bdb20-d0b7-4c05-ae7d-d6aa78662bad" class="uk-switcher uk-margin">

	<li>
<div>
<button class="helpbutton" data-toggle="chardinjs" onclick="$('body').chardinJs('start')"><object style="pointer-events: none;" type="image/svg+xml" data="/assets/images/help.svg"></object></button>
<div data-intro="Size of the sorting problem, 10..10,000,000 in powers of 10" data-position="bottom">
<div data-intro="Performance scale: Array.Sort (solid gray) is always 100%, and the other methods are scaled relative to it" data-position="left">
<div data-intro="Click legend items to show/hide series" data-position="right">
<div class="benchmark-chart-container">
<canvas data-chart="line">
N,100,1K,10K,64K,100K,1M,1.5M,10M
Jedi,         1   , 1  , 1 , 1  , 1   , 1  , 1  , 1
Overlined, 1.012312,    0.995069647, 0.904921232, 0.905092554, 0.915092554, 0.9212314, 0.929801383, 0.960170878

<!-- 
{ 
 "data" : {
  "datasets" : [
  { 
    "backgroundColor": "rgba(66,66,66,0.35)",
    "rough": { "fillStyle": "hachure", "hachureAngle": -30, "hachureGap": 9, "fillWeight": 0.3}
  },
  { 
    "backgroundColor": "rgba(33,220,33,.9)",
    "rough": { "fillStyle": "hachure", "hachureAngle": 60, "hachureGap": 3}
  }  
  ]
 },
 "options": {
    "title": { "text": "AVX2 Overlined Sorting - Scaled to Jedi", "display": true },
    "scales": { 
      "yAxes": [{
       "ticks": {
         "fontFamily": "Indie Flower",
         "min": 0.88, 
         "callback": "ticksPercent"
        },
        "scaleLabel": {
          "labelString": "Scaling (%)",
          "display": true
        }
      }]
    },
    "annotation": {
      "annotations": [{
        "drawTime": "afterDatasetsDraw",
        "type": "line",
        "mode": "vertical",
        "scaleID": "x-axis-0",
        "value": "1.5M",

        "borderColor": "#666666",
        "borderWidth": 2,
      "borderDash": [5, 5],
       "borderDashOffset": 5,
        "label": {
          "yAdjust": 5,
          "backgroundColor": "rgba(255, 0, 0, 0.75)",
          "fontFamily": "Indie Flower",
          "fontSize": 14,
          "content": "L3 Cache Size",
          "enabled": true
        }
      },
      {
        "drawTime": "afterDatasetsDraw",
        "type": "line",
        "mode": "vertical",
        "scaleID": "x-axis-0",
        "value": "64K",
        "borderColor": "#666666",
        "borderWidth": 2,
      "borderDash": [5, 5],
       "borderDashOffset": 5,
        "label": {
          "yAdjust": 65,
          "backgroundColor": "rgba(255, 0, 0, 0.75)",
          "fontFamily": "Indie Flower",
          "fontSize": 14,
          "content": "L2 Cache Size",
          "enabled": true
        }
      }]
    }
 },
 "defaultOptions": {"scales":{"xAxes":[{"scaleLabel":{"display":"true,","labelString":"N (elements)","fontFamily":"Indie Flower"},"ticks":{"fontFamily":"Indie Flower"}}]},"legend":{"display":true,"position":"bottom","labels":{"fontFamily":"Indie Flower","fontSize":14}},"title":{"position":"top","fontFamily":"Indie Flower","fontSize":16}}
}
--> </canvas>

</div>
</div>
</div>
</div>
</div>

</li>

	<li>
<div>
<button class="helpbutton" data-toggle="chardinjs" onclick="$('body').chardinJs('start')"><object style="pointer-events: none;" type="image/svg+xml" data="/assets/images/help.svg"></object></button>
<div data-intro="Size of the sorting problem, 10..10,000,000 in powers of 10" data-position="bottom">
<div data-intro="Time in nanoseconds spent sorting per element. Array.Sort (solid gray) is the baseline, again" data-position="left">
<div data-intro="Click legend items to show/hide series" data-position="right">
<div class="benchmark-chart-container">
<canvas data-chart="line">
N,100,1K,10K,100K,1M,10M
Jedi, 19.4547,  20.8907,  23.8802, 24.7229, 22.8053, 25.7011
Overlined, 20.092,  20.7878,  21.6097, 22.6238, 21.2044, 24.6774
<!-- 
{ 
 "data" : {
  "datasets" : [
  { 
    "backgroundColor": "rgba(66,66,66,0.35)",
    "rough": { "fillStyle": "hachure", "hachureAngle": -30, "hachureGap": 9, "fillWeight": 0.3}
  },
  { 
    "backgroundColor": "rgba(33,220,33,.9)",
    "rough": { "fillStyle": "hachure", "hachureAngle": 60, "hachureGap": 3}
  }
  ]
 },
 "options": {
    "title": { "text": "AVX2 Jedi Sorting + Overlined - log(Time/N)", "display": true },
    "scales": { 
      "yAxes": [{ 
        "type": "logarithmic",
        "ticks": {
          "min": 15,
          "max": 28,
          "callback": "ticksNumStandaard",
          "fontFamily": "Indie Flower"          
        },
        "scaleLabel": {
          "labelString": "Time/N (ns)",
          "fontFamily": "Indie Flower",
          "display": true
        }
      }]
    }
 },
 "defaultOptions": {"scales":{"xAxes":[{"scaleLabel":{"display":"true,","labelString":"N (elements)","fontFamily":"Indie Flower"},"ticks":{"fontFamily":"Indie Flower"}}]},"legend":{"display":true,"position":"bottom","labels":{"fontFamily":"Indie Flower","fontSize":14}},"title":{"position":"top","fontFamily":"Indie Flower","fontSize":16}}
}
--> </canvas>

</div>
</div>
</div>
</div>
</div>
</li>

	<li>
<div>
<button class="helpbutton" data-toggle="chardinjs" onclick="$('body').chardinJs('start')"><object style="pointer-events: none;" type="image/svg+xml" data="/assets/images/help.svg"></object></button>
<table class="table datatable" data-json="../_posts/Bench.BlogPt5_2_Int32_-report.datatable.json" data-id-field="name" data-pagination="false" data-page-list="[9, 18]" data-intro="Each row in this table represents a benchmark result" data-position="left" data-show-pagination-switch="false">
  <thead data-intro="The header can be used to sort/filter by clicking" data-position="right">
    <tr>
        <th data-field="TargetMethodColumn.Method" data-sortable="true" data-filter-control="select">
          <span data-intro="The name of the benchmarked method" data-position="top">
            Method<br>Name
          </span>
        </th>
        <th data-field="N" data-sortable="true" data-value-type="int" data-filter-control="select">
            <span data-intro="The size of the sorting problem being benchmarked (# of integers)" data-position="top">
            Problem<br>Size
            </span>
        </th>
        <th data-field="TimePerNDataTable" data-sortable="true" data-value-type="float2-interval-muted">
            <span data-intro="Time in nanoseconds spent sorting each element in the array (with confidence intervals in parenthesis)" data-position="top">
              Time /<br>Element (ns)
            </span>
        </th>
        <th data-field="RatioDataTable" data-sortable="true" data-value-type="inline-bar-horizontal-percentage">
            <span data-intro="Each result is scaled to its baseline (Array.Sort in this case)" data-position="top">
                  Scaling
            </span>
        </th>
        <th data-field="Measurements" data-sortable="true" data-value-type="inline-bar-vertical">
            <span data-intro="Raw benchmark results visualize how stable the result it. Longest/Shortest runs marked with &lt;span style='color: red'&gt;Red&lt;/span&gt;/&lt;span style='color: green'&gt;Green&lt;/span&gt;" data-position="top">Measurements</span>
        </th>
    </tr>
  </thead>
</table>
</div>

</li>

	<li>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td>
<td class="rouge-code"><pre><span class="nv">BenchmarkDotNet</span><span class="o">=</span>v0.12.0, <span class="nv">OS</span><span class="o">=</span>clear-linux-os 32120
Intel Core i7-7700HQ CPU 2.80GHz <span class="o">(</span>Kaby Lake<span class="o">)</span>, 1 CPU, 4 logical and 4 physical cores
.NET Core <span class="nv">SDK</span><span class="o">=</span>3.1.100
  <span class="o">[</span>Host]     : .NET Core 3.1.0 <span class="o">(</span>CoreCLR 4.700.19.56402, CoreFX 4.700.19.56404<span class="o">)</span>, X64 RyuJIT
  Job-DEARTS : .NET Core 3.1.0 <span class="o">(</span>CoreCLR 4.700.19.56402, CoreFX 4.700.19.56404<span class="o">)</span>, X64 RyuJIT

<span class="nv">InvocationCount</span><span class="o">=</span>3  <span class="nv">IterationCount</span><span class="o">=</span>15  <span class="nv">LaunchCount</span><span class="o">=</span>2
<span class="nv">UnrollFactor</span><span class="o">=</span>1  <span class="nv">WarmupCount</span><span class="o">=</span>10

<span class="nv">$ </span><span class="nb">grep</span> <span class="s1">'stepping\|model\|microcode'</span> /proc/cpuinfo | <span class="nb">head</span> <span class="nt">-4</span>
model           : 158
model name      : Intel<span class="o">(</span>R<span class="o">)</span> Core<span class="o">(</span>TM<span class="o">)</span> i7-7700HQ CPU @ 2.80GHz
stepping        : 9
microcode       : 0xb4
</pre></td>
</tr></tbody></table></code></pre></div></div>

</li>

</ul>

</div>

  <p>This is much better! The improvement is much more pronounced here, and we have a lot to consider:</p>

  <ul>
    <li>The performance improvements are not spread evenly through-out the size of the sorting problem.</li>
    <li>I’ve conveniently included two vertical markers, per my specific machine model, they show the size of the L2/L3 caches translated to <code class="highlighter-rouge">#</code> of 32-bit elements in our array.</li>
    <li>It can be clearly seen that as long as we’re sorting roughly within the size of our L2-L3 cache size range, this optimization pays in spades: we’re seeing ~10% speedup in runtime in many cases!</li>
    <li>It is also clear that as we progress outside the size of the L2 into the L3 cache size, and ultimately exhaust the size of our caches entirely, the returns on this optimization diminish gradually.</li>
    <li>While not shown here, since I’ve lost access to that machine, on older Intel/AMD machines, where only one load operation can be executed by the processor at any given time (Example: Intel Broadwell processors), this can lead to an improvement of 20% in total runtime; This should make sense: the less load ports the CPU has, the better this split-load reducing technique performs.</li>
    <li>Another thing to consider is that in future variations of this code when I finally get access and ability to use AVX-512, with 64-byte wide registers, the effects of this optimization will be much more pronounced again for a different reason: With vector registers spanning 64-bytes each, split-loading becomes a bigger problem (every single un-aligned read becomes a split-load). Therefore, removing it is even more important.</li>
  </ul>

</div>

<p>As the problem size goes beyond the size of the L2 cache, we are hit with the realities of CPU cache latency numbers. As service to the reader here is a visual representation for the <a href="https://www.7-cpu.com/cpu/Skylake_X.html">latency numbers for a Skylake-X CPU</a> running at 4.3 Ghz:</p>

<center>
<object style="margin: auto; width: 90%" type="image/svg+xml" data="../assets/images/latency.svg"></object>
</center>

<p>The small number of cycles we tack as the penalty of for split-loading (7 in this diagram) on to the memory operations is very real when we compare it to regular L1/L2 cache latency. But once we compare it to L3 or RAM latency, it becomes abundantly clear why we are seeing diminishing returns for this optimization; the penalty is simply too small to notice at those work points.</p>

<p>Finally, for this optimization, we must never forget our moto of trust no one and nothing. Let’s double check what the current state of affairs is as far as <code class="highlighter-rouge">perf</code> is concerned:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td>
<td class="rouge-code"><pre><span class="nv">$ </span>perf record <span class="nt">-Fmax</span> <span class="nt">-e</span> mem_inst_retired.split_loads <span class="se">\</span>
   ./Example <span class="nt">--type-list</span> DoublePumpOvelined <span class="nt">--size-list</span> 100000 <span class="se">\</span>
       <span class="nt">--max-loops</span> 1000 <span class="nt">--no-check</span>
<span class="nv">$ </span>perf report <span class="nt">--stdio</span> <span class="nt">-F</span> overhead,sym | <span class="nb">head</span> <span class="nt">-20</span>
<span class="c"># To display the perf.data header info, please use --header/--header-only options.</span>
<span class="c"># Samples: 129  of event 'mem_inst_retired.split_loads'</span>
<span class="c"># Event count (approx.): 12900387</span>
<span class="c"># Overhead  Symbol</span>
    30.23%  <span class="o">[</span>.] DoublePumpOverlined...::Sort<span class="o">(</span>int32<span class="k">*</span>,int32<span class="k">*</span>,int64,int32<span class="o">)</span>
    28.68%  <span class="o">[</span>.] DoublePumpOverlined...::VectorizedPartitionInPlace<span class="o">(</span>int32<span class="k">*</span>,int32<span class="k">*</span>,int64<span class="o">)</span>
    13.95%  <span class="o">[</span>.] __memmove_avx_unaligned_erms
     0.78%  <span class="o">[</span>.] JIT_MemSet_End
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>Seems like this moved the needle, and then some. We started with <code class="highlighter-rouge">86.68%</code> of <code class="highlighter-rouge">87,102,613</code> split-loads in our previous version of vectorized partitioning , and now we have <code class="highlighter-rouge">28.68%</code> of <code class="highlighter-rouge">12,900,387</code>. In other words: <code class="highlighter-rouge">(0.2668 * 12900387) / (0.8668 * 87102613)</code> gives us <code class="highlighter-rouge">4.55%</code>, or a <code class="highlighter-rouge">95.44%</code> reduction of split-load events for this version.
Not an entirely unpleasant experience.</p>

<h4 id="sub-optimization--converting-branches-to-arithmetic-1">Sub-optimization- Converting branches to arithmetic: <img class="emoji" title=":+1:" alt=":+1:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png" height="20" width="20">
</h4>

<p>By this time, my code contained quite a few branches to deal with various edge cases around alignment, and I pulled another rabbit out of the optimization hat that is worth mentioning: We can convert simple branches into arithmetic operations. Many times, we end up having branches with super simple code behind them; here’s a real example I used to have in my code, as part of some early version of overlinement, which we’ll try to optimize:</p>

<div>
  <div class="stickemup">

    <div class="language-csharp highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td>
<td class="rouge-code"><pre><span class="kt">int</span> <span class="n">leftAlign</span><span class="p">;</span>
<span class="p">...</span> <span class="c1">// Calculate left align here...</span>
<span class="k">if</span> <span class="p">(</span><span class="n">leftAlign</span> <span class="p">&lt;</span> <span class="m">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">readLeft</span> <span class="p">+=</span> <span class="m">8</span><span class="p">;</span>
<span class="p">}</span>
</pre></td>
</tr></tbody></table></code></pre></div>    </div>

  </div>

  <p>This looks awfully friendly, and it is unless <code class="highlighter-rouge">leftAlign</code> and therefore the entire branch is determined by random data we read from the array, making the CPU mispredict this branch too often than we’d care for it to happen. In my case, I had two branches like this, and each of them was happening at a rate of <code class="highlighter-rouge">1/8</code>. So enough for me to care. The good news is that we can re-write this, entirely in C#, and replace the potential misprediction with a constant, predictable (and often shorter!) data dependency. Let’s start by inspecting the re-written “branch”:</p>

</div>

<div>
  <div class="stickemup">

    <div class="language-csharp highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td>
<td class="rouge-code"><pre><span class="kt">int</span> <span class="n">leftAlign</span><span class="p">;</span>
<span class="p">...</span> <span class="c1">// Calculate left align here...</span>
<span class="c1">// Signed arithmetic FTW</span>
<span class="kt">var</span> <span class="n">leftAlignMask</span> <span class="p">=</span> <span class="n">leftAlign</span> <span class="p">&gt;&gt;</span> <span class="m">31</span><span class="p">;</span>
<span class="c1">// the mask is now either all 1s or all 0s depending on leftAlign's sign!</span>
<span class="n">readLeft</span> <span class="p">+=</span> <span class="m">8</span> <span class="p">&amp;</span> <span class="n">leftALignMask</span><span class="p">;</span>
</pre></td>
</tr></tbody></table></code></pre></div>    </div>

  </div>

  <p>By taking the same value we were comparing to 0 and right shifting it, we are performing an arithmetic right shift. This takes the top bit, which is either <code class="highlighter-rouge">0/1</code> depending on <code class="highlighter-rouge">leftAlign</code>’s sign bit, and essentially propagates it throughout the entire 32-bit value, which is then assigned to the <code class="highlighter-rouge">lestAlignMask</code> variable. We’ve essentially taken what was previously the result of the comparison as part of the branch (the sign bit), transforming it into a mask. We then proceed to take the mask and use it to control the outcome of the <code class="highlighter-rouge">+= 8</code> operation, effectively turning it into <em>either</em> a <code class="highlighter-rouge">+= 8</code> -or- a <code class="highlighter-rouge">+= 0</code> operation, depending on the value of the mask!<br>
This turns out to be a quite effective way, again, for simple branches only, at converting a potential misprediction event costing us 15 cycles, with a 100% constant 3-4 cycles data-dependency for the CPU: It can be thought as a “signaling” mechanism where we tell the CPU not to speculate on the result of the branch but instead complete the <code class="highlighter-rouge">readLeft +=</code> statement only after waiting for the right-shift (<code class="highlighter-rouge">&gt;&gt; 31</code>) and the bitwise and (<code class="highlighter-rouge">&amp;</code>) operation to propagate through its pipeline.</p>

  <table style="margin-bottom: 0em" class="notice--info">
<tr>
<td style="border: none; padding-top: 0; padding-bottom: 0; vertical-align: top"><span class="uk-label">Note</span></td>
<td style="border: none; padding-top: 0; padding-bottom: 0">
<div>
          <p>I referred to this as an old geezer’s optimization since modern processors already support this internally in the form of a <code class="highlighter-rouge">CMOV</code> instruction, which is more versatile, faster and takes up less bytes in the instruction stream while having the same “do no speculate on this” effect on the CPU. <em>The only issue</em> is we don’t have <code class="highlighter-rouge">CMOV</code> in the CoreCLR JIT (Mono’s JIT, peculiarly does support this both with the internal JIT and naturally with LLVM…).<br>
As a side note to this side note, I’ll add that this is such an old-dog trick that LLVM even detects such code and de-optimizes it back into a “normal” branch and then proceeds to optimize it again into <code class="highlighter-rouge">CMOV</code>, which I think is just a very cool thing, regardless :)</p>
        </div>
</td>
</tr>
</table>

</div>

<p>I ended up replacing about 5-6 super simple/small branches this way. I won’t show direct performance numbers for this, as this is already part of the overlined version; I can’t say it improved performance considerably for my test runs, but it did reduce the jitter of those runs, which can be seen in the reduced error bars and tighter confidence intervals shown in the benchmark results above.</p>

<h3 id="coming-to-terms-with-bad-speculation">Coming to terms with bad speculation</h3>

<p>At the end of part 3, we came to a hard realization that our code is badly speculating inside the CPU. Even after simplifying the branch code in our loop in part 4, the bad speculation remained there, staring at us persistently. If you recall, we experienced a lot of bad-speculation effects when sorting the data with our vectorized code, and profiling using hardware counters showed us that while <code class="highlighter-rouge">InsertionSort</code> was the cause of most of the bad-speculation events (41%), our vectorized code was still responsible for 32% of them. Let’s try to think about that mean nasty branch, stuck there, in the middle of our beautiful loop:</p>

<div>
  <div class="stickemup">

    <div class="language-csharp highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td>
<td class="rouge-code"><pre><span class="kt">int</span><span class="p">*</span> <span class="n">nextPtr</span><span class="p">;</span>
<span class="k">if</span> <span class="p">((</span><span class="kt">byte</span> <span class="p">*)</span> <span class="n">writeRight</span> <span class="p">-</span> <span class="p">(</span><span class="kt">byte</span> <span class="p">*)</span> <span class="n">readRight</span> <span class="p">&lt;</span> <span class="n">N</span> <span class="p">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">))</span> <span class="p">{</span>
    <span class="n">nextPtr</span>   <span class="p">=</span>  <span class="n">readRight</span><span class="p">;</span>
    <span class="n">readRight</span> <span class="p">-=</span> <span class="n">N</span><span class="p">;</span>
<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="n">nextPtr</span>  <span class="p">=</span>  <span class="n">readLeft</span><span class="p">;</span>
    <span class="n">readLeft</span> <span class="p">+=</span> <span class="n">N</span><span class="p">;</span>
<span class="p">}</span>

<span class="nf">PartitionBlock</span><span class="p">(</span><span class="n">nextPtr</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">pBase</span><span class="p">,</span> <span class="k">ref</span> <span class="n">writeLeft</span><span class="p">,</span> <span class="k">ref</span> <span class="n">writeRight</span><span class="p">);</span>
</pre></td>
</tr></tbody></table></code></pre></div>    </div>

  </div>

  <p>Long story short: We ended up sneaking up a data-based branch into our code in the form of this side-selection logic. Whenever we try to pick a side, we would read from next is where we put the CPU in a tough spot. We’re asking it to speculate on something it <em>can’t possibly speculate on successfully</em>. Our question is: “Oh CPU, CPU in the socket, Which side is closer to being over-written of them all?”, to which the answer is completely data-driven. In other words, it depends on how the last round(s) of partitioning mutated the pointers involved in the comparison. It might sound like an easy thing for the CPU to check, but we have to remember it is attempting to execute ~100 or so instructions into the future, as it is required to speculate on the result: the previous rounds of partitioning have not yet been fully-executed, internally. The CPU guesses, at best, based on stale data, and we know, as the grand designers of this mess, that its best guess is no better here than flipping a coin. Quite sad. You have to admit it is ironic we managed to do this whole big circle around our own tails just to come-back to having a branch misprediction based on the random array data. Mis-predicting here seems unavoidable. Or is it?</p>

  <h4 id="replacing-the-branch-with-arithmetic--1">Replacing the branch with arithmetic: <img class="emoji" title=":-1:" alt=":-1:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f44e.png" height="20" width="20">
</h4>

  <p>Could we replace this branch with arithmetic, just like we’ve done a couple of paragraphs above? Yes we can.
Consider this alternative version:</p>
</div>

<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td>
<td class="rouge-code"><pre><span class="kt">var</span> <span class="n">readRightMask</span> <span class="p">=</span>
    <span class="p">(((</span><span class="kt">byte</span><span class="p">*)</span> <span class="n">writeRight</span> <span class="p">-</span> <span class="p">(</span><span class="kt">byte</span><span class="p">*)</span> <span class="n">readRight</span> <span class="p">-</span> <span class="n">N</span><span class="p">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">)))</span> <span class="p">&gt;&gt;</span> <span class="m">63</span><span class="p">;</span>
<span class="kt">var</span> <span class="n">readLeftMask</span> <span class="p">=</span>  <span class="p">~</span><span class="n">readRightMask</span><span class="p">;</span>
<span class="c1">// If readRightMask is 0, we pick the left side</span>
<span class="c1">// If readLeftMask is 0, we pick the right side</span>
<span class="kt">var</span> <span class="n">readRightMaybe</span>  <span class="p">=</span> <span class="p">(</span><span class="kt">ulong</span><span class="p">)</span> <span class="n">readRight</span> <span class="p">&amp;</span> <span class="p">(</span><span class="kt">ulong</span><span class="p">)</span> <span class="n">readRightMask</span><span class="p">;</span>
<span class="kt">var</span> <span class="n">readLeftMaybe</span>   <span class="p">=</span> <span class="p">(</span><span class="kt">ulong</span><span class="p">)</span> <span class="n">readLeft</span>  <span class="p">&amp;</span> <span class="p">(</span><span class="kt">ulong</span><span class="p">)</span> <span class="n">readLeftMask</span><span class="p">;</span>

<span class="nf">PartitionBlock</span><span class="p">((</span><span class="kt">int</span> <span class="p">*)</span> <span class="p">(</span><span class="n">readLeftMaybe</span> <span class="p">+</span> <span class="n">readRightMaybe</span><span class="p">),</span>
               <span class="n">P</span><span class="p">,</span> <span class="n">pBase</span><span class="p">,</span> <span class="k">ref</span> <span class="n">writeLeft</span><span class="p">,</span> <span class="k">ref</span> <span class="n">writeRight</span><span class="p">);</span>

<span class="kt">var</span> <span class="n">postFixUp</span> <span class="p">=</span> <span class="p">-</span><span class="m">32</span> <span class="p">&amp;</span> <span class="n">readRightMask</span><span class="p">;</span>
<span class="n">readRight</span> <span class="p">=</span> <span class="p">(</span><span class="kt">int</span> <span class="p">*)</span> <span class="p">((</span><span class="kt">byte</span> <span class="p">*)</span> <span class="n">readRight</span> <span class="p">+</span> <span class="n">postFixUp</span><span class="p">);</span>
<span class="n">readLeft</span>  <span class="p">=</span> <span class="p">(</span><span class="kt">int</span> <span class="p">*)</span> <span class="p">((</span><span class="kt">byte</span> <span class="p">*)</span> <span class="n">readLeft</span>  <span class="p">+</span> <span class="n">postFixUp</span> <span class="p">+</span> <span class="m">32</span><span class="p">);</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>What the code above does, except for causing a nauseating headache, is taking the same concept of turning branches into arithmetic from the previous section and using it to get rid of that nasty branch: We take the comparison and turn it into a negative/positive number, then proceed to use it to generate masks we use to execute the code that used to reside under the branch.</p>

<p>I don’t want to dig deep into this. While its technically sound, and does what we need it to do, it’s more important to focus on how this performs:</p>

<div>
  <div class="stickemup">

<ul class="uk-tab" data-uk-switcher="{connect:'#8fc63529-869b-4c7d-aab5-2c2d25a929f2'}">

	<li class="uk-active"><a href="#"><i class="glyphicon glyphicon-stats"></i> Scaling</a></li>

	<li><a href="#"><i class="glyphicon glyphicon-stats"></i> Time/N</a></li>

	<li><a href="#"><i class="glyphicon glyphicon-list-alt"></i> Benchmarks</a></li>

	<li><a href="#"><i class="glyphicon glyphicon-info-sign"></i> Setup</a></li>

</ul>

<ul id="8fc63529-869b-4c7d-aab5-2c2d25a929f2" class="uk-switcher uk-margin">

	<li>
<div>
<button class="helpbutton" data-toggle="chardinjs" onclick="$('body').chardinJs('start')"><object style="pointer-events: none;" type="image/svg+xml" data="/assets/images/help.svg"></object></button>
<div data-intro="Size of the sorting problem, 10..10,000,000 in powers of 10" data-position="bottom">
<div data-intro="Performance scale: Array.Sort (solid gray) is always 100%, and the other methods are scaled relative to it" data-position="left">
<div data-intro="Click legend items to show/hide series" data-position="right">
<div class="benchmark-chart-container">
<canvas data-chart="line">
N,100,1K,10K,100K,1M,10M
Overlined,         1   , 1   , 1  , 1   , 1    , 1
Branchless, 0.87253937, 0.951842168, 1.104715689, 1.140662148, 1.253573179, 1.379499062

<!-- 
{ 
 "data" : {
  "datasets" : [
  { 
    "backgroundColor": "rgba(66,66,66,0.35)",
    "rough": { "fillStyle": "hachure", "hachureAngle": -30, "hachureGap": 9, "fillWeight": 0.3}
  },
  { 
    "backgroundColor": "rgba(33,220,33,.9)",
    "rough": { "fillStyle": "hachure", "hachureAngle": 60, "hachureGap": 3}
  }  
  ]
 },
 "options": {
    "title": { "text": "AVX2 Branchless Sorting - Scaled to Overlined", "display": true },
    "scales": { 
      "yAxes": [{
       "ticks": {
         "fontFamily": "Indie Flower",
         "min": 0.80, 
         "callback": "ticksPercent"
        },
        "scaleLabel": {
          "labelString": "Scaling (%)",
          "display": true
        }
      }]
    }
 },
 "defaultOptions": {"scales":{"xAxes":[{"scaleLabel":{"display":"true,","labelString":"N (elements)","fontFamily":"Indie Flower"},"ticks":{"fontFamily":"Indie Flower"}}]},"legend":{"display":true,"position":"bottom","labels":{"fontFamily":"Indie Flower","fontSize":14}},"title":{"position":"top","fontFamily":"Indie Flower","fontSize":16}}
}
--> </canvas>

</div>
</div>
</div>
</div>
</div>

</li>

	<li>
<div>
<button class="helpbutton" data-toggle="chardinjs" onclick="$('body').chardinJs('start')"><object style="pointer-events: none;" type="image/svg+xml" data="/assets/images/help.svg"></object></button>
<div data-intro="Size of the sorting problem, 10..10,000,000 in powers of 10" data-position="bottom">
<div data-intro="Time in nanoseconds spent sorting per element. Array.Sort (solid gray) is the baseline, again" data-position="left">
<div data-intro="Click legend items to show/hide series" data-position="right">
<div class="benchmark-chart-container">
<canvas data-chart="line">
N,100,1K,10K,100K,1M,10M
Overlined, 20.3199,21.0354,21.6787,23.0622,23.246,24.7603
Branchless, 17.7252,20.0221,23.9488,26.3062,29.1405,34.1567

<!-- 
{ 
 "data" : {
  "datasets" : [
  { 
    "backgroundColor": "rgba(66,66,66,0.35)",
    "rough": { "fillStyle": "hachure", "hachureAngle": -30, "hachureGap": 9, "fillWeight": 0.3}
  },
  { 
    "backgroundColor": "rgba(33,220,33,.9)",
    "rough": { "fillStyle": "hachure", "hachureAngle": 60, "hachureGap": 3}
  }
  ]
 },
 "options": {
    "title": { "text": "AVX2 Jedi Sorting + Aligned - log(Time/N)", "display": true },
    "scales": { 
      "yAxes": [{ 
        "type": "logarithmic",
        "ticks": {
          "min": 15,
          "max": 35,
          "callback": "ticksNumStandaard",
          "fontFamily": "Indie Flower"          
        },
        "scaleLabel": {
          "labelString": "Time/N (ns)",
          "fontFamily": "Indie Flower",
          "display": true
        }
      }]
    }
 },
 "defaultOptions": {"scales":{"xAxes":[{"scaleLabel":{"display":"true,","labelString":"N (elements)","fontFamily":"Indie Flower"},"ticks":{"fontFamily":"Indie Flower"}}]},"legend":{"display":true,"position":"bottom","labels":{"fontFamily":"Indie Flower","fontSize":14}},"title":{"position":"top","fontFamily":"Indie Flower","fontSize":16}}
}
--> </canvas>

</div>
</div>
</div>
</div>
</div>
</li>

	<li>
<div>
<button class="helpbutton" data-toggle="chardinjs" onclick="$('body').chardinJs('start')"><object style="pointer-events: none;" type="image/svg+xml" data="/assets/images/help.svg"></object></button>
<table class="table datatable" data-json="../_posts/Bench.BlogPt5_3_Int32_-report.datatable.json" data-id-field="name" data-pagination="false" data-page-list="[9, 18]" data-intro="Each row in this table represents a benchmark result" data-position="left" data-show-pagination-switch="false">
  <thead data-intro="The header can be used to sort/filter by clicking" data-position="right">
    <tr>
        <th data-field="TargetMethodColumn.Method" data-sortable="true" data-filter-control="select">
          <span data-intro="The name of the benchmarked method" data-position="top">
            Method<br>Name
          </span>
        </th>
        <th data-field="N" data-sortable="true" data-value-type="int" data-filter-control="select">
            <span data-intro="The size of the sorting problem being benchmarked (# of integers)" data-position="top">
            Problem<br>Size
            </span>
        </th>
        <th data-field="TimePerNDataTable" data-sortable="true" data-value-type="float2-interval-muted">
            <span data-intro="Time in nanoseconds spent sorting each element in the array (with confidence intervals in parenthesis)" data-position="top">
              Time /<br>Element (ns)
            </span>
        </th>
        <th data-field="RatioDataTable" data-sortable="true" data-value-type="inline-bar-horizontal-percentage">
            <span data-intro="Each result is scaled to its baseline (Array.Sort in this case)" data-position="top">
                  Scaling
            </span>
        </th>
        <th data-field="Measurements" data-sortable="true" data-value-type="inline-bar-vertical">
            <span data-intro="Raw benchmark results visualize how stable the result it. Longest/Shortest runs marked with &lt;span style='color: red'&gt;Red&lt;/span&gt;/&lt;span style='color: green'&gt;Green&lt;/span&gt;" data-position="top">Measurements</span>
        </th>
    </tr>
  </thead>
</table>
</div>

</li>

	<li>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td>
<td class="rouge-code"><pre><span class="nv">BenchmarkDotNet</span><span class="o">=</span>v0.12.0, <span class="nv">OS</span><span class="o">=</span>clear-linux-os 32120
Intel Core i7-7700HQ CPU 2.80GHz <span class="o">(</span>Kaby Lake<span class="o">)</span>, 1 CPU, 4 logical and 4 physical cores
.NET Core <span class="nv">SDK</span><span class="o">=</span>3.1.100
  <span class="o">[</span>Host]     : .NET Core 3.1.0 <span class="o">(</span>CoreCLR 4.700.19.56402, CoreFX 4.700.19.56404<span class="o">)</span>, X64 RyuJIT
  Job-DEARTS : .NET Core 3.1.0 <span class="o">(</span>CoreCLR 4.700.19.56402, CoreFX 4.700.19.56404<span class="o">)</span>, X64 RyuJIT

<span class="nv">InvocationCount</span><span class="o">=</span>3  <span class="nv">IterationCount</span><span class="o">=</span>15  <span class="nv">LaunchCount</span><span class="o">=</span>2
<span class="nv">UnrollFactor</span><span class="o">=</span>1  <span class="nv">WarmupCount</span><span class="o">=</span>10

<span class="nv">$ </span><span class="nb">grep</span> <span class="s1">'stepping\|model\|microcode'</span> /proc/cpuinfo | <span class="nb">head</span> <span class="nt">-4</span>
model           : 158
model name      : Intel<span class="o">(</span>R<span class="o">)</span> Core<span class="o">(</span>TM<span class="o">)</span> i7-7700HQ CPU @ 2.80GHz
stepping        : 9
microcode       : 0xb4
</pre></td>
</tr></tbody></table></code></pre></div></div>

</li>

</ul>

</div>

  <p>Look, I’m not here to sugar-coat it: This looks like an unmitigated disaster. But I claim that it is one we can learn a lot from in the future.
With the exception of sorting <code class="highlighter-rouge">&lt;= 100</code> elements, as the problem grows, the situation is getting much worse.</p>

  <p>To double-check that everything is sound, I ran <code class="highlighter-rouge">perf</code> recording the <code class="highlighter-rouge">instructions</code>, <code class="highlighter-rouge">branches</code> and <code class="highlighter-rouge">branch-misses</code> events for both versions for sorting <code class="highlighter-rouge">100,000</code> elements.</p>

  <p>The command line used was this:</p>

  <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td>
<td class="rouge-code"><pre><span class="nv">$ </span>perf record <span class="nt">-F</span> max <span class="nt">-e</span> instructions,branches,branch-misses <span class="se">\</span>
    ./Example <span class="nt">--type-list</span> DoublePumpOverlined <span class="se">\</span>
              <span class="nt">--size-list</span> 100000 <span class="nt">--max-loops</span> 1000 <span class="nt">--no-check</span>
<span class="nv">$ </span>perf record <span class="nt">-F</span> max <span class="nt">-e</span> instructions,branches,branch-misses <span class="se">\</span>
    ./Example <span class="nt">--type-list</span> DoublePumpBranchless <span class="se">\</span>
              <span class="nt">--size-list</span> 100000 <span class="nt">--max-loops</span> 1000 <span class="nt">--no-check</span>
</pre></td>
</tr></tbody></table></code></pre></div>  </div>

  <p>If you’re one of those sick people who likes to look into other people’s sorrows, here is a <a href="https://gist.github.com/damageboy/79368e350364348c6ca476492a63f052">gist with the full results</a>, if you’re more normal, and to keep things simple, I’ve processed the results and presenting them here in table form:</p>

  <center>
<object style="margin: auto; width: 90%" type="image/svg+xml" data="../assets/images/overlined-branchless-counters.svg"></object>
</center>

</div>

<p>This is pretty amazing if you think about it:</p>

<ul>
  <li>The number of branches was cut in half: This makes sense, the loop control itself is a branch instuction after all, so it remains even in the <code class="highlighter-rouge">Branchless</code> variant.</li>
  <li>The branches that remain in the <code class="highlighter-rouge">branchless</code> version are all easy to predict, and we see that the <code class="highlighter-rouge">branch-misses</code> counter shows us those are down to nothing.<br>
This means that there is no mistake: We succeeded in a targeted assassination of that branch; however, there was a lot of collateral damage…</li>
  <li>The verbiage of the branchless code, expressed in the <code class="highlighter-rouge">instructions</code> counter is definitely costing us something here:<br>
The number of executed instructions inside our partition loop have gone up by 17%, which is a lot.</li>
</ul>

<p>The slowdown we’ve measured here is directly related to NOT having <code class="highlighter-rouge">CMOV</code> available to us through the CoreCLR JIT. but I really don’t think that this is the entire story here. It’s hard to express this in words, but
the slope at which the branchless code is slowing down compared to the previous version is very suspicious in my eyes.<br>
There is an expression we use in Hebrew a lot for this sort of situation: “The operation was successful, but the patient died”. There is no question that this is one of those moments.
This failure to accelerate the sorting operation, and specifically the way it fails, increasingly as the problem size grows, is very telling in my eyes.
I have an idea of why this is and how we might be able to go around it. But, for today, our time is up. I’ll try and get back to this much much later in this series,
and hopefully, we’ll all be wiser for it.</p>

<hr>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:0" role="doc-endnote">
      <p>Remember that the CPU knows nothing about two different cache-lines. They might actually be on a page boundary as well, which means they might be in two different DRAM chips, or perhaps, a single split-line access causes our poor CPU to communicate with a different socket, where another memory controller is responsible to reading the memory from its own DRAM modules! <a href="#fnref:0" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
    <li id="fn:1" role="doc-endnote">
      <p>Most modern Intel CPUs can actually address the L1 cache units twice per cycle, at least when it comes to reading data, by virtue of having two load-ports. That means they can actually request two cache-line as the same time! But this still causes more load on the cache and bus. In our case, we must also remember we will be reading an additional cache-line for our permutation entry… <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>This specific AVX2 intrinsic will actually fail if/when used on non-aligned addresses. But it is important to note that it seems it won’t actually run faster than the previous load intrinsic we’ve used: <code class="highlighter-rouge">AVX2.LoadDquVector256</code> as long as the actual addresses we pass to both instructions are 32-byte aligned. In other words, it’s very useful for debugging alignment issues, but not that critical to actually call that intrinsic! <a href="#fnref:2" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>I could be wrong about that last statement, but I couldn’t find anything quite like this discussed anywhere, and believe me, I’ve searched. If anyone can point me out to someone doing this before, I’d really love to hear about it; there might be more good stuff to read about there… <a href="#fnref:3" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
  </ol>
</div>

        
      </section>

      <footer class="page__meta">
        
        


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2020-02-02T02:22:28+00:00">February 02, 2020</time></p>
        
      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=This+Goes+to+Eleven+%28Pt.+5%2F%E2%88%9E%29%20https%3A%2F%2Fbits.houmus.org%2F2020-02-02%2Fthis-goes-to-eleven-pt5" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fbits.houmus.org%2F2020-02-02%2Fthis-goes-to-eleven-pt5" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fbits.houmus.org%2F2020-02-02%2Fthis-goes-to-eleven-pt5" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/2020-02-01/this-goes-to-eleven-pt4" class="pagination--pager" title="This Goes to Eleven (Pt. 4/∞)
">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2020-02-01/this-goes-to-eleven-pt4" rel="permalink">This Goes to Eleven (Pt. 4/∞)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  78 minute read

</p>
    
    <p class="archive__item-excerpt" itemprop="description">Decimating Array.Sort with AVX2. I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics. There’s no reason I should go down...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2020-01-30/this-goes-to-eleven-pt3" rel="permalink">This Goes to Eleven (Part. 3/∞)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  83 minute read

</p>
    
    <p class="archive__item-excerpt" itemprop="description">Decimating Array.Sort with AVX2. I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics. There’s no reason I should go down...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2020-01-29/this-goes-to-eleven-pt2" rel="permalink">This Goes to Eleven (Part. 2/∞)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  31 minute read

</p>
    
    <p class="archive__item-excerpt" itemprop="description">Decimating Array.Sort with AVX2. I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics. There’s no reason I should go down...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2020-01-28/this-goes-to-eleven-pt1" rel="permalink">This Goes to Eleven (Part 1/∞)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  39 minute read

</p>
    
    <p class="archive__item-excerpt" itemprop="description">Decimating Array.Sort with AVX2. I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics. There’s no reason I should go down...</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap">
<div class="search-searchbar"></div>
  <div class="search-hits"></div>
</div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">© 2020 damageboy. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>


<!-- Including InstantSearch.js library and styling -->
<script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch-theme-algolia.min.css">

<script>
// Instanciating InstantSearch.js with Algolia credentials
const search = instantsearch({
  appId: 'CMJJV3VL7A',
  apiKey: 'f1673463105fd4295fbbeffc415b5934',
  indexName: 'bits.houmus.org',
  searchParameters: {
    restrictSearchableAttributes: [
      'title',
      'content'
    ]
  }
});

const hitTemplate = function(hit) {
  const url = hit.url;
  const title = hit._highlightResult.title.value;
  const content = hit._highlightResult.html.value;

  return `
    <div class="list__item">
      <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
        <h2 class="archive__item-title" itemprop="headline"><a href="${url}">${title}</a></h2>
        <div class="archive__item-excerpt" itemprop="description">${content}</div>
      </article>
    </div>
  `;
}

// Adding searchbar and results widgets
search.addWidget(
  instantsearch.widgets.searchBox({
    container: '.search-searchbar',
    poweredBy: true,
    placeholder: 'Enter your search term...'
  })
);
search.addWidget(
  instantsearch.widgets.hits({
    container: '.search-hits',
    templates: {
      item: hitTemplate
    }
  })
);

// Starting the search
search.start();
</script>





  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-124434205-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-124434205-1', { 'anonymize_ip': false});
</script>








<div class="top-scroll-progress-bar"></div>


<script>
jQuery( document ).ready(function() {
    jQuery('table.datatable').each(function(){
        jQuery(this).datatable();
    });
});
</script>

<script>
  var element = document.documentElement,
    body = document.body,
    scrollTop = 'scrollTop',
    scrollHeight = 'scrollHeight',
    progress = document.querySelector('.top-scroll-progress-bar'),
    scroll;
  
  document.addEventListener('scroll', function() {
    scroll = (element[scrollTop]||body[scrollTop]) / ((element[scrollHeight]||body[scrollHeight]) - element.clientHeight) * 100;
    progress.style.setProperty('--scroll', scroll + '%');
  });
  </script>


  </body>
</html>
