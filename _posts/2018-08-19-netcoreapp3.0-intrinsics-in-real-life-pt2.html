<p>As I’ve described in <a href="/2018-08-18/netcoreapp3.0-intrinsics-in-real-life-pt1">part 1</a> of this series, I’ve recently overhauled an internal data structure we use at Work<sup>®</sup> to start using <a href="https://github.com/dotnet/designs/blob/master/accepted/platform-intrinsics.md">platform dependent intrinsics</a>.</p>

<p>If you’ve not read part 1 yet, I suggest you do so, since we continue right where we left off…</p>

<p>As a reminder, this series is made in 3 parts:</p>

<ul>
  <li><a href="/2018-08-18/netcoreapp3.0-intrinsics-in-real-life-pt1">The data-structure/operation that we’ll optimize and basic usage of intrinsics</a>.</li>
  <li>Using intrinsics more effectively (this post).</li>
  <li><a href="/2018-08-20/netcoreapp3.0-intrinsics-in-real-life-pt3">The C++ version(s) of the corresponding C# code, and what I learned from them</a>.</li>
</ul>

<p>All of the code (C# &amp; C++) is published under the <a href="https://github.com/damageboy/bitgoo">bitgoo github repo</a>.</p>

<h3 id="pdep---parallel-bit-deposit">PDEP - Parallel Bit Deposit</h3>

<p>We’re about to twist our heads with a bit of a challenge: For me, this was a lot of fun, since I got to play with something I knew <em>nothing</em> about which turned out to be very useful, and not only for this specific task, but useful in general.</p>

<p>We’re going to optimize a subset of this method’s performance “spectrum”: lower bit counts.<br />
If you go back to the previous iteration of the code, we can clearly see that apart from the one 64 bit <code class="highlighter-rouge">POPCNT</code> loop up at the top, the ratio between instructions executed and bits processed for low values of <code class="highlighter-rouge">N</code> doesn’t look too good. I summed up the instruction counts from the JIT Dump linked above:</p>

<ul>
  <li>The 64-bit <code class="highlighter-rouge">POPCNT</code> loop takes 10 instructions, split into two fragments of the function, processing 64 bits each iteration.</li>
  <li>The rest of the code (31 instructions not including the <code class="highlighter-rouge">ret</code>!) is spent processing the last &lt;= 64 bits, executing a single time.</li>
</ul>

<p>While just counting instructions isn’t the best profiling metric in the world, it’s still very revealing…<br />
Wouldn’t it be great if we could do something to improve that last, long code fragment?
Guess what…<br />
Yes we can! using a weird little instruction called <a href="https://en.wikipedia.org/wiki/Bit_Manipulation_Instruction_Sets#Parallel_bit_deposit_and_extract"><code class="highlighter-rouge">PDEP</code></a> whose description (copy-pasted from <a href="https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-instruction-set-reference-manual-325383.pdf">Intel’s bible of instructions</a> in page 922) goes like this:</p>

<blockquote>
  <p>PDEP uses a mask in the second source operand (the third operand) to transfer/scatter contiguous low order bits in the first source operand (the second operand) into the destination (the first operand). PDEP takes the low bits from the first source operand and deposit them in the destination operand at the corresponding bit locations that are set in the second source operand (mask). All other bits (bits not set in mask) in destination are set to zero.</p>
</blockquote>

<p>Luckily, it comes with a diagram that makes is more digestible:</p>

<p><img src="/assets/images/pdep.svg" alt="PDEP" /></p>

<p>I know this might be a bit intimidating at first, but what <code class="highlighter-rouge">PDEP</code> can do for us, in my own words, is this: Process a single 64-bit value (<code class="highlighter-rouge">SRC1</code>) according to a mask of bits (<code class="highlighter-rouge">SRC2</code>) and copy (“deposit”) the least-significant bits from <code class="highlighter-rouge">SRC1</code> (or from right to left in the diagram) into a destination register according to the the position of <code class="highlighter-rouge">1</code> bits in the mask (<code class="highlighter-rouge">SRC2</code>).<br />
It definitely takes time to wrap your head around how/what can be done with this, and there are many more applications than just this bit-searching. To be honest, right after I read a <a href="http://palms.ee.princeton.edu/PALMSopen/hilewitz06FastBitCompression.pdf">paper</a> about <code class="highlighter-rouge">PDEP</code>, which from what I gathered, was the inspiration that led to having these primitives in our processors and an extremely good paper for those willing to dive deeper, I felt like a hammer in search of a nail, in wanting to apply this somewhere, until I remembered I had <em>this</em> little thing I need (e.g. this function) and I tried using it, still in C++, about 2 years ago…<br />
It took me a good day of goofing around (I actually started with its sister instruction <code class="highlighter-rouge">PEXT</code> ) with this on a white-board until I finally saw <em>a</em> solution…
<u>*Note*</u>: There might be other solutions, better than what I came up with, and if anyone reading this finds one, I would love to hear about it!</p>

<p>For those of you who don’t like spoilers, this might be a good time to grab a piece of paper and try to figure out how <code class="highlighter-rouge">PDEP</code> could help us in processing the last 64 bits, where we know our target bit is hiding…</p>

<p>If you are ready for the solution, I’ll just show the one-liner C# expression that replaces the <strong>31</strong> instructions we saw the JIT emit for us to handle those last &lt; 64 bits in our bitmap all the way town to <strong>13</strong> instructions and just as importantly: with <strong>0</strong> branching:</p>

<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="c1">// Where:</span>
<span class="c1">// n is the # of the target bit we are searching for</span>
<span class="c1">// value is the 64 bits when we know for sure that n is "hiding" within</span>
<span class="kt">var</span> <span class="n">offsetOfNthBit</span> <span class="p">=</span> <span class="nf">TrailingZeroCount</span><span class="p">(</span>
                         <span class="nf">ParallelBitDeposit</span><span class="p">(</span><span class="m">1U</span><span class="n">L</span> <span class="p">&lt;&lt;</span> <span class="p">(</span><span class="n">n</span> <span class="p">-</span> <span class="m">1</span><span class="p">),</span> <span class="k">value</span><span class="p">);</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>It’s not trivial to see how/why this works just from reading the code, so lets break this down, for an imaginary case of a 16-bit <code class="highlighter-rouge">PDEP</code> and assorted registers, for simplicity:</p>

<p>As an example, let’s pretend we are are looking for the offset (position) of the 8<sup>th</sup> <code class="highlighter-rouge">1</code> bit.<br />
We pass two operands to <code class="highlighter-rouge">ParallelBitDeposit()</code>:<br />
The <code class="highlighter-rouge">SRC1</code> operand has the value of <code class="highlighter-rouge">1</code> left shifted by the bit number we are searching for minus 1, so for our case of <code class="highlighter-rouge">n = 8</code>, we shift a single <code class="highlighter-rouge">1</code> bit 7 bits to the left, ending up with:</p>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="err">0b_0000_0000_1000_0000</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Our “fake” 16-bit <code class="highlighter-rouge">SRC1</code> now has a single <code class="highlighter-rouge">1</code> bit in the <strong>position</strong> that equals our target-bit <strong>count</strong> (This last emphasis is important!)
Remember that by this point in our search function, we have made sure our <code class="highlighter-rouge">n</code> is within the range <code class="highlighter-rouge">1..64</code>, so <code class="highlighter-rouge">n-1</code> can only be <code class="highlighter-rouge">0..63</code> we we can never shift negative number of bits, or above the size of the register (this can be seen more easily in the full code listing below).</p>

<p>As for <code class="highlighter-rouge">SRC2</code>,  We load it up with our remaining portion of the bitmap, whose n<sup>th</sup> lit bit position we are searching for, so with careful mashing of the keyboard, I came up with these random bits:</p>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="err">0b_0001_0111_0011_0110</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This is what executing <code class="highlighter-rouge">PDEP</code> with these two operands does:</p>

<p><img src="/assets/images/pdep-bitsearch-example-animated.svg" alt="PDEP" /></p>

<p>By now, we’ve managed to generate a temporary value where only our original target-bit remains lit, in its original position, so thanks for that, <code class="highlighter-rouge">PDEP</code>! In a way, we’ve managed to tweak <code class="highlighter-rouge">PDEP</code> into a custom masking opcode, capable of masking out the first <code class="highlighter-rouge">n-1</code> lit bits…<br />
Finally, all that remains is to use the BMI1 <code class="highlighter-rouge">TZCNT</code> instruction to count the number of <code class="highlighter-rouge">0</code> bits leading up to our deposited <code class="highlighter-rouge">1</code> bit marker. That number ends up being the offset of the n<sup>th</sup> lit bit in the original bitmap! Cool, eh?</p>

<p>Let’s look at the final code for this function:</p>

<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="rouge-code"><pre><span class="k">using</span> <span class="nn">static</span> <span class="n">System</span><span class="p">.</span><span class="n">Runtime</span><span class="p">.</span><span class="n">Intrinsics</span><span class="p">.</span><span class="n">X86</span><span class="p">.</span><span class="n">Popcnt</span><span class="p">;</span>
<span class="k">using</span> <span class="nn">static</span> <span class="n">System</span><span class="p">.</span><span class="n">Runtime</span><span class="p">.</span><span class="n">Intrinsics</span><span class="p">.</span><span class="n">X86</span><span class="p">.</span><span class="n">Bmi1</span><span class="p">;</span>
<span class="k">using</span> <span class="nn">static</span> <span class="n">System</span><span class="p">.</span><span class="n">Runtime</span><span class="p">.</span><span class="n">Intrinsics</span><span class="p">.</span><span class="n">X86</span><span class="p">.</span><span class="n">Bmi2</span><span class="p">;</span>

<span class="k">public</span> <span class="k">static</span> <span class="k">unsafe</span> <span class="kt">int</span> <span class="nf">POPCNTAndBMI2</span><span class="p">(</span><span class="kt">ulong</span><span class="p">*</span> <span class="n">bits</span><span class="p">,</span> <span class="kt">int</span> <span class="n">numBits</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">var</span> <span class="n">p64</span> <span class="p">=</span> <span class="n">bits</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">prevN</span><span class="p">;</span>
    <span class="k">do</span> <span class="p">{</span>
        <span class="n">prevN</span> <span class="p">=</span> <span class="n">n</span><span class="p">;</span>
        <span class="n">n</span> <span class="p">-=</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="nf">PopCount</span><span class="p">(*</span><span class="n">p64</span><span class="p">);</span>
        <span class="n">p64</span><span class="p">++;</span>
    <span class="p">}</span> <span class="k">while</span> <span class="p">(</span><span class="n">n</span> <span class="p">&gt;</span> <span class="m">0</span><span class="p">);</span>

    <span class="n">p64</span><span class="p">--;</span>
    <span class="c1">// Here, we know for sure that 1 .. prevN .. 64 (including)</span>
    <span class="kt">var</span> <span class="n">pos</span> <span class="p">=</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="nf">TrailingZeroCount</span><span class="p">(</span>
                        <span class="nf">ParallelBitDeposit</span><span class="p">(</span><span class="m">1U</span><span class="n">L</span> <span class="p">&lt;&lt;</span> <span class="p">(</span><span class="n">prevN</span> <span class="p">-</span> <span class="m">1</span><span class="p">),</span> <span class="p">*</span><span class="n">p64</span><span class="p">));</span>
    <span class="k">return</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="p">((</span><span class="n">p64</span> <span class="p">-</span> <span class="n">bits</span><span class="p">)</span> <span class="p">&lt;&lt;</span> <span class="m">6</span><span class="p">)</span> <span class="p">+</span> <span class="n">pos</span><span class="p">;</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>With the code out of the way, time to see if the whole thing paid off?</p>

<table>
  <thead>
    <tr>
      <th>Method</th>
      <th>N</th>
      <th style="text-align: right">Mean (ns)</th>
      <th style="text-align: right">Scaled to “POPCNTAndBMI1”</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>POPCNTAndBMI2</td>
      <td>1</td>
      <td style="text-align: right">2.232</td>
      <td style="text-align: right">0.95</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2</td>
      <td>4</td>
      <td style="text-align: right">9.497</td>
      <td style="text-align: right">0.62</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2</td>
      <td>16</td>
      <td style="text-align: right">40.259</td>
      <td style="text-align: right">0.34</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2</td>
      <td>64</td>
      <td style="text-align: right">193.253</td>
      <td style="text-align: right">0.19</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2</td>
      <td>256</td>
      <td style="text-align: right">1,581.082</td>
      <td style="text-align: right">0.32</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2</td>
      <td>1024</td>
      <td style="text-align: right">23,174.989</td>
      <td style="text-align: right">0.51</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2</td>
      <td>4096</td>
      <td style="text-align: right">341,087.341</td>
      <td style="text-align: right">0.82</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2</td>
      <td>16384</td>
      <td style="text-align: right">4,979,229.288</td>
      <td style="text-align: right">0.95</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2</td>
      <td>65536</td>
      <td style="text-align: right">76,144,935.381</td>
      <td style="text-align: right">0.98</td>
    </tr>
  </tbody>
</table>

<p>Oh boy did it! results are much better for the lower counts of <code class="highlighter-rouge">N</code>:</p>

<ul>
  <li>As expected, the scaling improved with <em>peak improvement</em> compared to the previous version at <code class="highlighter-rouge">N==64</code>, with a 400% speedup compared to the previous version!</li>
  <li>As N grows beyond 64, this version’s performance resembles the previous version’s more and more (duh!).</li>
</ul>

<p>All in all, everything looks as we would have expected so far…<br />
Again, for those interested, here’s a <a href="https://gist.github.com/9b049a464dc66237500454ed367a79aa">gist</a> of the JITDump, for your pleasure.</p>

<h3 id="loop-unrolling">Loop Unrolling</h3>

<p>A common optimization technique we haven’t used up to this point, is <a href="https://en.wikipedia.org/wiki/Loop_unrolling">loop unrolling/unwinding</a>:</p>

<blockquote>
  <p>The goal of loop unwinding is to increase a program’s speed by reducing 
or eliminating instructions that control the loop, such as <a href="https://en.wikipedia.org/wiki/Pointer_arithmetic">pointer arithmetic</a> and “end of loop” tests on each iteration;[<a href="https://en.wikipedia.org/wiki/Loop_unrolling#cite_note-1">1]</a> reducing branch penalties; as well as hiding latencies including the delay in reading data from memory.[<a href="https://en.wikipedia.org/wiki/Loop_unrolling#cite_note-2">2]</a> To eliminate this <a href="https://en.wikipedia.org/wiki/Computational_overhead">computational overhead</a>, loops can be re-written as a repeated sequence of similar independent statements.[<a href="https://en.wikipedia.org/wiki/Loop_unrolling#cite_note-3">3]</a></p>
</blockquote>

<p>By now, we’re left with only one loop, so clearly the target of loop unrolling is the <code class="highlighter-rouge">POPCNT</code> loop.<br />
After all, we are potentially going over thousands of bits, and by shoving more <code class="highlighter-rouge">POPCNT</code> instructions in between the looping instructions, we can theoretically drive the CPU harder.<br />
Not only that, but modern (in this case x86/x64) CPUs are notorious for having internal parallelism that comes in many shapes and forms. For <code class="highlighter-rouge">POPCNT</code> specifically, we know from <a href="https://www.agner.org/optimize/instruction_tables.pdf">Agner Fog’s Instruction Tables</a> that:</p>

<ul>
  <li>Intel Skylake can execute certain <code class="highlighter-rouge">POPCNT</code> instructions on two different execution ports, with a single <code class="highlighter-rouge">POPCNT</code> latency of 3 cycles, and a reciprocal throughput of 1 cycle, so a latency of <code class="highlighter-rouge">x + 2</code> cycles as a best case, where <code class="highlighter-rouge">x</code> is the number of <strong>continuous independent</strong> <code class="highlighter-rouge">POPCNT</code> instructions.</li>
  <li>AMD Ryzen can execute up to 4 <code class="highlighter-rouge">POPCNT</code> instructions in 1 cycle, with a latency of 1 cycle, for <strong>continuous independent</strong>  <code class="highlighter-rouge">POPCNT</code> instructions, which is even more impressive (I’ve not yet been able to verify this somewhat extravagant claim…).</li>
</ul>

<p>These numbers were measured on real CPUs, with very specific benchmarks that measure single independent instructions. They should <strong>not</strong> be taken as a target performance for <strong>our</strong> code, since we are attempting to solve a real-life problem, which isn’t limited to a single instruction and has at least SOME dependency between the different instructions and branching logic on top of that.<br />
But the numbers do give us at least one thing: motivation to unroll our <code class="highlighter-rouge">POPCNT</code> loop and try to get more work out of the CPU by issuing independent <code class="highlighter-rouge">POPCNT</code> on different parts of our bitmap.</p>

<p>Here’s the code that does this:</p>

<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td class="rouge-code"><pre><span class="k">using</span> <span class="nn">static</span> <span class="n">System</span><span class="p">.</span><span class="n">Runtime</span><span class="p">.</span><span class="n">Intrinsics</span><span class="p">.</span><span class="n">X86</span><span class="p">.</span><span class="n">Popcnt</span><span class="p">;</span>
<span class="k">using</span> <span class="nn">static</span> <span class="n">System</span><span class="p">.</span><span class="n">Runtime</span><span class="p">.</span><span class="n">Intrinsics</span><span class="p">.</span><span class="n">X86</span><span class="p">.</span><span class="n">Bmi1</span><span class="p">;</span>
<span class="k">using</span> <span class="nn">static</span> <span class="n">System</span><span class="p">.</span><span class="n">Runtime</span><span class="p">.</span><span class="n">Intrinsics</span><span class="p">.</span><span class="n">X86</span><span class="p">.</span><span class="n">Bmi2</span><span class="p">;</span>

<span class="k">public</span> <span class="k">static</span> <span class="k">unsafe</span> <span class="kt">int</span> <span class="nf">POPCNTAndBMI2Unrolled</span><span class="p">(</span><span class="kt">ulong</span><span class="p">*</span> <span class="n">bits</span><span class="p">,</span> <span class="kt">int</span> <span class="n">numBits</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">var</span> <span class="n">p64</span> <span class="p">=</span> <span class="n">bits</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(;</span> <span class="n">n</span> <span class="p">&gt;=</span> <span class="m">256</span><span class="p">;</span> <span class="n">p64</span> <span class="p">+=</span> <span class="m">4</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">n</span> <span class="p">-=</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="p">(</span>
            <span class="nf">PopCount</span><span class="p">(</span><span class="n">p64</span><span class="p">[</span><span class="m">0</span><span class="p">])</span> <span class="p">+</span>
            <span class="nf">PopCount</span><span class="p">(</span><span class="n">p64</span><span class="p">[</span><span class="m">1</span><span class="p">])</span> <span class="p">+</span>
            <span class="nf">PopCount</span><span class="p">(</span><span class="n">p64</span><span class="p">[</span><span class="m">2</span><span class="p">])</span> <span class="p">+</span>
            <span class="nf">PopCount</span><span class="p">(</span><span class="n">p64</span><span class="p">[</span><span class="m">3</span><span class="p">]));</span>
    <span class="p">}</span>
    <span class="kt">var</span> <span class="n">prevN</span> <span class="p">=</span> <span class="n">n</span><span class="p">;</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">n</span> <span class="p">&gt;</span> <span class="m">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">prevN</span> <span class="p">=</span> <span class="n">n</span><span class="p">;</span>
        <span class="n">n</span> <span class="p">-=</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="nf">PopCount</span><span class="p">(*</span><span class="n">p64</span><span class="p">);</span>
        <span class="n">p64</span><span class="p">++;</span>
    <span class="p">}</span>

    <span class="n">p64</span><span class="p">--;</span>
    <span class="kt">var</span> <span class="n">pos</span> <span class="p">=</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="nf">TrailingZeroCount</span><span class="p">(</span>
                        <span class="nf">ParallelBitDeposit</span><span class="p">(</span><span class="m">1U</span><span class="n">L</span> <span class="p">&lt;&lt;</span> <span class="p">(</span><span class="n">prevN</span> <span class="p">-</span> <span class="m">1</span><span class="p">),</span> <span class="p">*</span><span class="n">p64</span><span class="p">));</span>
    <span class="k">return</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="p">((</span><span class="n">p64</span> <span class="p">-</span> <span class="n">bits</span><span class="p">)</span> <span class="p">*</span> <span class="m">64</span><span class="p">)</span> <span class="p">+</span> <span class="n">pos</span><span class="p">;</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We had to change the code flow to account for the unrolled loop, but all in all this is pretty straight forward, so let’s see how this performs:</p>

<table>
  <thead>
    <tr>
      <th>Method</th>
      <th>N</th>
      <th style="text-align: right">Mean (ns)</th>
      <th style="text-align: right">Scaled to POPCNTAndBMI2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>POPCNTAndBMI2Unrolled</td>
      <td>1</td>
      <td style="text-align: right">2.249</td>
      <td style="text-align: right">1.04</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2Unrolled</td>
      <td>4</td>
      <td style="text-align: right">10.904</td>
      <td style="text-align: right">1.15</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2Unrolled</td>
      <td>16</td>
      <td style="text-align: right">50.368</td>
      <td style="text-align: right">1.11</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2Unrolled</td>
      <td>64</td>
      <td style="text-align: right">208.272</td>
      <td style="text-align: right">1.13</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2Unrolled</td>
      <td>256</td>
      <td style="text-align: right">1,580.026</td>
      <td style="text-align: right">0.99</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2Unrolled</td>
      <td>1024</td>
      <td style="text-align: right">21,282.905</td>
      <td style="text-align: right">0.92</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2Unrolled</td>
      <td>4096</td>
      <td style="text-align: right">255,186.977</td>
      <td style="text-align: right">0.74</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2Unrolled</td>
      <td>16384</td>
      <td style="text-align: right">3,730,420.068</td>
      <td style="text-align: right">0.77</td>
    </tr>
    <tr>
      <td>POPCNTAndBMI2Unrolled</td>
      <td>65536</td>
      <td style="text-align: right">56,939,817.593</td>
      <td style="text-align: right">0.76</td>
    </tr>
  </tbody>
</table>

<p>There are a few interesting things going on here:</p>

<ul>
  <li>For low bit-counts (<code class="highlighter-rouge">N &lt;= 64</code>) we can see a drop in performance compared to the previous version. That is totally acceptable: We’ve made the code longer and more branch-y, and all of this was done in order to gain some serious change on the other side of this benchmark (Also, in reality, no one ever complains that your code used to take 193ns, but is now taking 208ns :).</li>
  <li>In other words: The drop is not horrible, And we hope to make up enough for it on higher bit counts.</li>
  <li>And we are making up for it, kind of… We can see a 33%-ish speedup for <code class="highlighter-rouge">N &gt;= 4096</code>.</li>
</ul>

<p>For those interested, here’s the <a href="https://gist.github.com/c73959ad3dfe31e5d65e6bf273f53211">JITDump</a> of this version.</p>

<p>In theory, we should be happy, pack our bags, and call it a day! We’ve done it, we’ve squeezed every last bit we could hope to.<br />
<strong>Except we really didn’t…</strong><br />
While it might not be clear from these results alone, the loop unrolling hit an unexpected snag: the performance improvement is actually disappointing.<br />
How can I tell? Well, that’s simple: <strong>I’m cheating!</strong><br />
I’ve already written parallel C++ code as part of this whole effort (to be honest, I wrote the C++ code two years before C# intrinsics were a thing), and I’ve seen where unrolled <code class="highlighter-rouge">POPCNT</code> can go, and this is not it.<br />
Not <em>yet</em> at least.</p>

<p>From my C++ attempts, I know we should have seen a ~100% speedup in high bit-counts with loop unrolling, but we are seeing much less than that.</p>

<p>To understand why though, and what is really going on here, you’ll have to wait for the next post, where we cover some of the C++ code, and possibly learn more about processors than we cared to know…</p>

<h2 id="mid-journey-conclusions">Mid-Journey Conclusions</h2>

<p>We’ve taken our not so bad code at the end of the first post and improved upon quite a lot!<br />
I hope you’ve seen how trying to think outside the box, and finding creative ways to compound various intrinsics provided by the CPU can really pay off in performance, and even simplicity.</p>

<p>With the positive things, we must also not forget there are some negative sides to working with intrinsics, which by now, you might also begin sensing them:</p>

<ul>
  <li>You’ll need to map which CPUs your users are using, and which CPU intrinsics are supported on each model (even within a single architecture, such as Intel/AMD x64 you’ll see great variation throughout different models!).</li>
  <li>You’ll sometimes need to cryptic implementation-selection code, that uses the provided <code class="highlighter-rouge">.IsHardwareAccelerated</code> properties (for example detecting <code class="highlighter-rouge">BMI1</code> only CPUs vs. <code class="highlighter-rouge">BMI1</code> + <code class="highlighter-rouge">BMI2</code> ones) to steer the JIT into the “best” implementation, while praying to the powers that be that the JIT will be intelligent enough to elide the un-needed code at generation time, and still inline the resulting code.</li>
  <li>Due to having multiple implementations, architecture specific <em>testing</em> becomes a new requirement.
This might sound basic to a C++ developer, but less so for C#/CLR developers; this would mean that you need to have access to x86 (both 32 and 64 bit) ,arm32,arm64 test agents and run tests on <strong>all of them</strong> to be able to sleep calmly at night.</li>
</ul>

<p>All of these are considerations to be taken seriously, especially if you work outside of Microsoft (where there are considerably more resources for testing, and greater impact for using intrinsics at the same time), while considering intrinsics.</p>

<p>In the <a href="/2018-08-20/netcoreapp3.0-intrinsics-in-real-life-pt3">next and final post</a>, we’ll explore the performance bug I uncovered, and how generally C# compares to C++ for this sort of code…</p>
