<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.17.2 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>This Goes to Eleven (Part. 2/∞) - damageboy</title>
<meta name="description" content="Decimating Array.Sort with AVX2. I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics. There’s no reason I should go down alone.">


  <meta name="author" content="damageboy">


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="damageboy">
<meta property="og:title" content="This Goes to Eleven (Part. 2/∞)">
<meta property="og:url" content="https://bits.houmus.org/2020-01-29/this-goes-to-eleven-pt2">


  <meta property="og:description" content="Decimating Array.Sort with AVX2. I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics. There’s no reason I should go down alone.">



  <meta property="og:image" content="https://bits.houmus.org/assets/images/these-go-to-eleven.jpg">





  <meta property="article:published_time" content="2020-01-29T05:26:28+00:00">






<link rel="canonical" href="https://bits.houmus.org/2020-01-29/this-goes-to-eleven-pt2">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": null,
      "url": "https://bits.houmus.org/"
    
  }
</script>


  <meta name="google-site-verification" content="wcrvaF3e88-Vb6y-9eUTqYaXDMOukzl4c-IdKByS0Xc" />


  <meta name="msvalidate.01" content="6D5AE23298671D95A20FAD7FA3430ABB">




<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="damageboy Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->
<link rel="apple-touch-icon" sizes="180x180" href="/assets/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/favicons/site.webmanifest">
<link rel="mask-icon" href="/assets/favicons/safari-pinned-tab.svg" color="#ba0000">
<link rel="shortcut icon" href="/assets/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="damageboy">
<meta name="application-name" content="damageboy">
<meta name="msapplication-TileColor" content="#ba0000">
<meta name="msapplication-config" content="/assets/favicons/browserconfig.xml">
<meta name="theme-color" content="#ba0000ff">

<!-- <link rel="stylesheet" type="text/css" href="/assets/css/inlineDisqussions.css" /> -->
<script src="/assets/scripts/webfont.js"></script>
<script>
WebFont.load({
  google: {
    families: ['Lato', 'Indie Flower']
  },
  custom: {
    families: ['Cascadia Code'],
    urls: ['/assets/css/cascadia.css']
  }
});
</script>


<script defer src="/assets/scripts/jquery.min.js"></script>
<script defer src="/assets/scripts/polyfill.min.js"></script>
<script defer src="/assets/scripts/config-mathjax.js"></script>
<script defer src="/assets/scripts/tex-chtml-full.js"></script>
<!-- <script defer src="/assets/scripts/inlineDisqussions.js"></script> -->
<script defer src="/assets/scripts/uikit.min.js"></script>
<script defer src="/assets/scripts/uikit-icons.min.js"></script>
<script defer src="/assets/scripts/roughjs@3.1.0"></script>
<script defer src="/assets/scripts/Chart.bundle.min.js"></script>
<script defer src="/assets/scripts/chartjs-plugin-rough@0.2.0"></script>
<script defer src="/assets/scripts/chartjs-plugin-annotation.js"></script>
<!-- <script defer src="/assets/scripts/applyInlineDisqussions.js"></script> -->
<script defer src="/assets/scripts/inline-chartjs.js"></script>

<link href="/assets/css/chardinjs.css" rel="stylesheet">
<script defer src="/assets/scripts/chardinjs.min.js"></script>

<!-- This is entirely for the  datatable.js -->
<link rel="stylesheet" href="/assets/css/bootstrap.css">
<link rel="stylesheet" href="/assets/css/bootstrap-table.min.css"> 
<link rel="stylesheet" href="/assets/css/bootstrap-table-filter-control.min.css">
<link rel="stylesheet" href="/assets/css/datatable.css">

<script defer src="/assets/scripts/bootstrap.min.js"></script>
<script defer src="/assets/scripts/bootstrap-table.min.js"></script>
<script defer src="/assets/scripts/bootstrap-table-filter-control.min.js"></script>
<script defer src="/assets/scripts/moment.min.js"></script>
<script defer type="text/javascript" src="/assets/scripts/datatable.js"></script>

  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          damageboy
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/" >Posts</a>
            </li><li class="masthead__menu-item">
              <a href="/talks/" >Talks</a>
            </li><li class="masthead__menu-item">
              <a href="/about/" >About</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  











<div class="page__hero--overlay"
  style=" background-image: linear-gradient(rgba(106, 0, 0, 0.6), rgba(106, 0, 0, 0.6)), url('/assets/images/these-go-to-eleven.jpg'), url('/assets/images/these-go-to-eleven.webp');"
>
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          This Goes to Eleven (Part. 2/∞)

        
      </h1>
      
        <p class="page__lead">Decimating Array.Sort with AVX2.<br /><br /> I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics.<br /> There’s no reason I should go down alone.
</p>
      
      
        <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  31 minute read

</p>
      
      
      
        <p>
        
          
          <a href="https://github.com/damageboy/vxsort" class="btn btn--light-outline btn--large">GitHub</a>
        
          
          <a href="https://www.nuget.org/packages/VxSort" class="btn btn--light-outline btn--large">Nuget</a>
        
      
    </div>
  
  
</div>





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/assets/images/atari.svg" alt="damageboy" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">damageboy</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>What did I do this time?</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      
        <li>
          <a href="https://bits.houmus.org" itemprop="url">
            <i class="fas fa-fw fa-link" aria-hidden="true"></i> Website
          </a>
        </li>
      

      
        <li>
          <a href="mailto:dans@houmus.org">
            <meta itemprop="email" content="dans@houmus.org" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email
          </a>
        </li>
      

      

      
        <li>
          <a href="https://twitter.com/damageboy" itemprop="sameAs" rel="nofollow noopener noreferrer">
            <i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      
        <li>
          <a href="https://stackoverflow.com/users/9172/damageboy" itemprop="sameAs" rel="nofollow noopener noreferrer">
            <i class="fab fa-fw fa-stack-overflow" aria-hidden="true"></i> Stack Overflow
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="This Goes to Eleven (Part. 2/∞)">
    <meta itemprop="description" content="Decimating Array.Sort with AVX2. I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics. There’s no reason I should go down alone.">
    <meta itemprop="datePublished" content="January 29, 2020">
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
        <p>Since there’s a lot to over go over here, I’ve split it up into no less than 6 parts:</p>

<ol>
  <li>In <a href="/2020-01-28/this-goes-to-eleven-pt1">part 1</a>, we start with a refresher on <code class="highlighter-rouge">QuickSort</code> and how it compares to <code class="highlighter-rouge">Array.Sort()</code>.</li>
  <li>In this part, we go over the basics of vectorized hardware intrinsics, vector types, and go over a handful of vectorized instructions we’ll use in part 3. We still won’t be sorting anything.</li>
  <li>In <a href="/2020-01-30/this-goes-to-eleven-pt3">part 3</a>, we go through the initial code for the vectorized sorting, and start seeing some payoff. We finish agonizing courtesy of the CPU’s branch predictor, throwing a wrench into our attempts.</li>
  <li>In part 4, we go over a handful of optimization approaches that I attempted trying to get the vectorized partitioning to run faster. We’ll see what worked and what didn’t.</li>
  <li>In part 5, we’ll see how we can almost get rid of all the remaining scalar code- by implementing small-constant size array sorting. We’ll use, drum roll…, yet more AVX2 vectorization.</li>
  <li>Finally, in part 6, I’ll list the outstanding stuff/ideas I have for getting more juice and functionality out of my vectorized code.</li>
</ol>

<h2 id="intrinsics--vectorization">Intrinsics / Vectorization</h2>

<p>I’ll start by repeating my own words from the first <a href="/2018-08-18/netcoreapp3.0-intrinsics-in-real-life-pt1#the-whatwhy-of-intrinsics">blog post where I discussed intrinsics</a> in the CoreCLR 3.0 alpha days:</p>

<blockquote>
  <p>Processor intrinsics are a way to directly embed specific CPU instructions via special, fake method calls that the JIT replaces at code-generation time. Many of these instructions are considered exotic, and normal language syntax cannot map them cleanly.<br />
The general rule is that a single intrinsic “function” becomes a single CPU instruction.</p>
</blockquote>

<p>You can go and re-read that introduction if you care for a more general and gentle introduction to processor intrinsics. For this series, we are going to focus on vectorized intrinsics in Intel processors. This is the largest group of CPU specific intrinsics in our processors, and I want to start by showing this by the numbers. I gathered some statistics by processing Intel’s own <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/files/data-3.4.6.xml">data-3.4.6.xml</a>. This XML file is part of the <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">Intel Intrinsics Guide</a>, an invaluable resource on intrinsics in itself, and the “database” behind the guide. What I learned was that:</p>

<ul>
  <li>There are no less than 1,218 intrinsics in Intel processors<sup id="fnref:0" role="doc-noteref"><a href="#fn:0" class="footnote">1</a></sup>!
    <ul>
      <li>Those can be combined in 6,180 different ways (according to operand sizes and types).</li>
      <li>They’re grouped into 67 different categories/groups, these groups loosely correspond to various generations of CPUs as more and more intrinsics were gradually added.</li>
    </ul>
  </li>
  <li>More than 94% are vectorized hardware intrinsics, which we’ll define more concretely below.</li>
</ul>

<p>That last point is super-critical: CPU intrinsics, at least in 2020, are overwhelmingly about being able to execute vectorized instructions. That’s really why you <em>should</em> be paying them attention in the first place. Sure, there’s additional stuff in there: if you’re a kernel developer, or writing crypto code, or some other niche-cases, but vectorization is why you are really here, whether you knew it or not.</p>

<p>In C#, we’ve mostly shied away from having intrinsics until CoreCLR 3.0 came along, where intrinsic support became official/complete, championed by <a href="https://twitter.com/tannergooding">@tannergooding</a> as well as others from Microsoft and Intel. but as single-threaded performance has virtually stopped improving, more programming languages started adding intrinsics support (go, rust, Java and now C#) so developers in those languages would have access to these specialized, much more efficient instructions. CoreCLR 3.0 does not support all 1,218 intrinsics that I found, but a more modest 226 intrinsics in <a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86?view=netcore-3.0&amp;viewFallbackFrom=dotnet-plat-ext-3.0">15 different classes</a> for x86 Intel and AMD processors. Each class is filled with many static functions, all of which are unique processor intrinsics, and represent a 1:1 mapping to Intel group/code names. As C# developers, we roughly get access to everything that Intel incorporated in their processors manufactured from 2014 and onwards<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">2</a></sup>, and for AMD processors, from 2015 onwards.</p>

<p>What are these vectorized intrinsics?<br />
We need to cover a few base concepts specific to that category of intrinsics before we can start explaining specific intrinsics/instructions:</p>

<ul>
  <li>What are vectorized intrinsics, and why have they become so popular.</li>
  <li>How vectorized intrinsics interact with specialized vectorized <em>registers</em>.</li>
  <li>How those registers are reflected as, essentially, new primitive types in CoreCLR 3.0.</li>
</ul>

<h3 id="simd-what--why">SIMD What &amp; Why</h3>

<p>I’m going to use vectorization and SIMD interchangeably from here-on, but for the first and last time, let’s spell out what SIMD is: <strong>S</strong>ingle <strong>I</strong>nstruction <strong>M</strong>ultiple <strong>D</strong>ata is really a simple idea when you think about it. A lot of code ends up doing “stuff” in loops, usually, processing vectors of data one element at a time. SIMD instructions bring a simple new idea to the table: The CPU adds special instructions that can do arithmetic, bit-operations, comparisons and many other types of generalized operations on “vectors”, e.g. process multiple elements per instruction.</p>

<p>The benefit of using this approach to computing is that it allows for much greater efficiency: When we use vectorized intrinsics we end up executing the same <em>number</em> of instructions to process, for example, 8 data elements per instruction. Therefore, we reduce the amount of time the CPU spends decoding instructions for the same amount of work; furthermore, most vectorized instructions operate <em>independently</em> on the various <strong>elements</strong> of the vector and complete their operation at the same number of CPU cycles as the equivalent non-vectorized (or scalar) instruction. In short, in the land of CPU feature economics, vectorization is considered a high bang-for-buck feature: You can get a lot of <em>potential</em> performance for relatively little transistors added to the CPU, as long as people are willing to adapt their code (e.g. rewrite it) to use these new intrinsics, or compilers somehow magically manage to auto-vectorize the code (spoiler: There are tons of problems with that too)<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">3</a></sup>.</p>

<p>Another equally important thing to embrace and understand about vectorized intrinsics is what they don’t and cannot provide: branching. It’s pretty much impossible to even attempt to imagine what a vectorized branch instruction would mean. These two concepts don’t begin to mix. Appropriately, a substantial part of vectorizing code is forcing oneself to accomplishing the given task without using branching. As we will see, branching begets unpredictability, at the CPU level, and unpredictability is our enemy, when we want to go fast.</p>

<p>Of course, I’m grossly over-romanticizing vectorized intrinsics and their benefits: There are also many non-trivial overheads involved both using them and adding them to our processors and to using them in our code. However, all in all, in the grand picture of CPU/performance economics adding and using vectorized instructions is still, compared to other potential improvements, quite cheap, under the assumption that programmers are willing to make the effort to re-write and maintain vectorized code.</p>

<h4 id="simd-registers">SIMD registers</h4>

<p>After our short introduction to vectorized intrinsics, we need to discuss SIMD registers, and how this piece of the puzzle fits the grand picture: Teaching our CPU to execute 1,000+ vectorized instructions is just part of the story, these instructions need to somehow operate on our data. Do all of these instructions simply take a pointer to memory and run wild with it? The short answer is: <strong>No</strong>. For the <em>most</em> part, CPU instructions dealing with vectorization (with a few notable exceptions) use special registers inside our CPU that are called SIMD registers. This is analogous to scalar (regular, non-vectorized) code we write in any programming language: while some instructions read and write directly to memory, and occasionally some instruction will accept a memory address as an operand, most instructions are register ↔ register only.</p>

<p>Just like scalar CPU registers, SIMD registers have a constant bit-width. In Intel these come at 64, 128, 256 and recently 512 bit wide registers. Unlike scalar registers, though, SIMD registers, end up <em>containing multiple</em> data-elements of another primitive type. The same register can and will be used to process a wide-range of primitive data-types, depending on which instruction is using it, as we will shortly demonstrate.</p>

<p>For now, this is all I care to explain about SIMD Registers at the CPU level: We need to be aware of their existence (we’ll see them in disassembly dumps anyway), and since we are dealing with high-perfomance code we kind of need to know how many of them exist inside our CPU.</p>

<h4 id="simd-intrinsic-types-in-c">SIMD Intrinsic Types in C\#</h4>

<p>We’ve touched lightly upon SIMD intrinsics and how they operate (e.g. accept and modify) on SIMD registers. Time to figure out how we can fiddle with everything in C#; we’ll start with the types:</p>

<table>
  <thead>
    <tr>
      <th>C# Type</th>
      <th style="text-align: center">x86 Registers</th>
      <th style="text-align: center">Width (bits)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.vector64?view=netcore-3.0"><code class="highlighter-rouge">Vector64&lt;T&gt;</code></a></td>
      <td style="text-align: center"><code class="highlighter-rouge">mmo-mm7</code></td>
      <td style="text-align: center">64</td>
    </tr>
    <tr>
      <td><a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.vector128?view=netcore-3.0"><code class="highlighter-rouge">Vector128&lt;T&gt;</code></a></td>
      <td style="text-align: center"><code class="highlighter-rouge">xmm0-xmm15</code></td>
      <td style="text-align: center">128</td>
    </tr>
    <tr>
      <td><a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.vector256?view=netcore-3.0"><code class="highlighter-rouge">Vector256&lt;T&gt;</code></a></td>
      <td style="text-align: center"><code class="highlighter-rouge">ymm0-ymm15</code></td>
      <td style="text-align: center">256</td>
    </tr>
  </tbody>
</table>

<p>These are primitive vector value-types recognized by the JIT while it is generating machine code. We should try and think about these types just like we think about other special-case primitive types such as <code class="highlighter-rouge">int</code> or <code class="highlighter-rouge">double</code>, with one exception: These vector types all accept a generic parameter <code class="highlighter-rouge">&lt;T&gt;</code>, which may seem a little odd for a primitive type at a first glance, until we remember that their purpose is to contain <em>other</em> primitive types (there’s a reason they put the word “Vector” in there…); moreover, this generic parameter can’t just be any type or even value-type we’d like… It is limited to the types supported on our CPU and its vectorized intrinsics.</p>

<p>Let’s take <code class="highlighter-rouge">Vector256&lt;T&gt;</code>, which I’ll be using exclusively in this series, as an example; <code class="highlighter-rouge">Vector256&lt;T&gt;</code> can be used <strong>only</strong> with the following primitive types:</p>

<table class="fragment">
<thead><th style="border: none"><code>typeof(T)</code></th>
<th />
<th style="border: none"># Elements</th>
<th style="border: none"></th>
<th style="border: none">Element Width (bits)</th>
</thead>
<tbody>
<tr><td style="border: none"><code>byte / sbyte</code></td>  <td style="border: none">➡</td><td style="border: none">32</td><td style="border: none">x</td><td style="border: none">8b</td></tr>
<tr><td style="border: none"><code>short / ushort</code></td><td style="border: none">➡</td> <td style="border: none">16</td><td style="border: none">x</td><td style="border: none">16b</td></tr>
<tr><td style="border: none"><code>int / uint</code></td>    <td style="border: none">➡</td> <td style="border: none">8</td><td style="border: none">x</td><td style="border: none">32b</td></tr>
<tr><td style="border: none"><code>long / ulong</code></td>  <td style="border: none">➡</td> <td style="border: none">4</td><td style="border: none">x</td><td style="border: none">64b</td></tr>
<tr><td style="border: none"><code>float</code></td><td style="border: none">➡</td> <td style="border: none">8</td><td style="border: none">x</td><td style="border: none">32b</td></tr>
<tr><td style="border: none"><code>double</code></td> <td style="border: none">➡</td> <td style="border: none">4</td><td style="border: none">x</td><td style="border: none">64b</td></tr>
    </tbody>
</table>

<p>No matter which type of the supported primitive set we’ll choose, we’ll end up with a total of 256 bits, or the underlying SIMD register width.<br />
Now that we’ve kind of figured out of vector types/registers are represented in C#, let’s perform some operations on them.</p>

<h3 id="a-few-vectorized-instructions-for-the-road">A few Vectorized Instructions for the road</h3>

<p>Armed with this new understanding and knowledge of <code class="highlighter-rouge">Vector256&lt;T&gt;</code> we can move on and start learning a few vectorized instructions.</p>

<p>Chekhov famously said: “If in the first act you have hung a pistol on the wall, then in the following one it should be fired. Otherwise, don’t put it there”. Here are seven loaded AVX2 pistols; rest assured they are about to fire in the next act. I’m obviously not going to explain all 1,000+ intrinsics mentioned before, if only not to piss off Anton Chekhov. We will <strong>thoroughly</strong> explain the ones needed to get this party going.<br />
Here’s the list of what we’re going to go over:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">x64 asm</th>
      <th style="text-align: center">Intel</th>
      <th style="text-align: right">CoreCLR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">vbroadcastd</code></td>
      <td style="text-align: center"><a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm256_broadcastd_epi32&amp;expand=542"><code class="highlighter-rouge">_mm256_broadcastd_epi32</code></a></td>
      <td style="text-align: right"><a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.vector256.create?view=netcore-3.0#System_Runtime_Intrinsics_Vector256_Create_System_Int32_"><code class="highlighter-rouge">Vector256.Create(int)</code></a></td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">vlddqu</code></td>
      <td style="text-align: center"><a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm256_lddqu_si256&amp;expand=3296"><code class="highlighter-rouge">_mm256_lddqu_si256</code></a></td>
      <td style="text-align: right"><a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.avx.loaddquvector256?view=netcore-3.0#System_Runtime_Intrinsics_X86_Avx_LoadDquVector256_System_Int32__"><code class="highlighter-rouge">Avx.LoadDquVector256</code></a></td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">vmovdqu</code></td>
      <td style="text-align: center"><a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm256_storeu_si256&amp;expand=5654"><code class="highlighter-rouge">_mm256_storeu_si256</code></a></td>
      <td style="text-align: right"><a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.avx.store?view=netcore-3.0#System_Runtime_Intrinsics_X86_Avx_Store_System_Int32__System_Runtime_Intrinsics_Vector256_System_Int32__"><code class="highlighter-rouge">Avx.Store</code></a></td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">vpcmpgtd</code></td>
      <td style="text-align: center"><a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm256_cmpgt_epi32&amp;expand=900"><code class="highlighter-rouge">_mm256_cmpgt_epi32</code></a></td>
      <td style="text-align: right"><a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.avx2.comparegreaterthan?view=netcore-3.0#System_Runtime_Intrinsics_X86_Avx2_CompareGreaterThan_System_Runtime_Intrinsics_Vector256_System_Int32__System_Runtime_Intrinsics_Vector256_System_Int32__"><code class="highlighter-rouge">Avx2.CompareGreaterThan</code></a></td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">vmovmskps</code></td>
      <td style="text-align: center"><a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm256_movemask_ps&amp;expand=3870"><code class="highlighter-rouge">_mm256_movemask_ps</code></a></td>
      <td style="text-align: right"><a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.avx.movemask?view=netcore-3.0#System_Runtime_Intrinsics_X86_Avx_MoveMask_System_Runtime_Intrinsics_Vector256_System_Single__"><code class="highlighter-rouge">Avx.MoveMask</code></a></td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">popcnt</code></td>
      <td style="text-align: center"><a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm_popcnt_u32&amp;expand=4378"><code class="highlighter-rouge">_mm_popcnt_u32</code></a></td>
      <td style="text-align: right"><a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.popcnt.popcount?view=netcore-3.0#System_Runtime_Intrinsics_X86_Popcnt_PopCount_System_UInt32_"><code class="highlighter-rouge">Popcnt.PopCount</code></a></td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="highlighter-rouge">vpermd</code></td>
      <td style="text-align: center"><a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm256_permutevar8x32_epi32&amp;expand=4201"><code class="highlighter-rouge">_mm256_permutevar8x32_epi32</code></a></td>
      <td style="text-align: right"><a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.avx2.permutevar8x32?view=netcore-3.0#System_Runtime_Intrinsics_X86_Avx2_PermuteVar8x32_System_Runtime_Intrinsics_Vector256_System_Int32__System_Runtime_Intrinsics_Vector256_System_Int32__"><code class="highlighter-rouge">Avx2.PermuteVar8x32</code></a></td>
    </tr>
  </tbody>
</table>

<p>I understand that for first time readers, this list looks like I’m just name-dropping lots of fancy code names to make myself sound smart, but the unfortunate reality is that we <em>kind of need</em> to know all of these, and here is why: On the right column I’ve provided the actual C# Intrinsic function we will be calling in our code and linked to their docs. But here’s a funny thing: There is no “usable” documentation on Microsoft’s own docs regarding most of these intrinsics. All those docs do is simply point back to the Intel C/C++ intrinsic name, which I’ve also provided in the middle column, with links to the real documentation, the sort that actually explains what the instruction does with pseudo code. Finally, since we’re practically writing assembly code anyways, and I can guarantee we’ll end up inspecting JIT’d code down the road, I provided the x86 assembly opcodes for our instructions as well.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">4</a></sup>
Now, What does each of these do? Let’s find out…</p>

<table style="margin-bottom: 0em" class="notice--info">
<tr>
<td style="border: none"><span class="uk-label">Hint</span></td>
<td style="border: none">From here-on, The following icon means I have a thingy that animates: <object style="margin: auto; position: relative; top: 1.1em" type="image/svg+xml" data="../talks/intrinsics-sorting-2019/play.svg"></object><br />
Click/Touch/Hover <b>inside</b> means: <i class="glyphicon glyphicon-play"></i><br />
Click/Touch/Hover <b>outside</b> means: <i class="glyphicon glyphicon-pause"></i>
</td>
</tr>
</table>

<h4 id="vector256createint-value">Vector256.Create(int value)</h4>

<div>
  <div class="stickemup">
    <object class="animated-border" width="100%" type="image/svg+xml" data="../talks/intrinsics-sorting-2019/inst-animations/vbroadcast-with-hint.svg"></object>
  </div>

  <p>We start with a couple of simple instructions, and nothing is more simple than this first: This intrinsic accepts a single scalar value and simply “broadcasts” it to an entire SIMD register, this is how you’d use it:</p>

  <div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">Vector256</span><span class="p">&lt;</span><span class="kt">int</span><span class="p">&gt;</span> <span class="n">someVector256</span> <span class="p">=</span> <span class="n">Vector256</span><span class="p">.</span><span class="nf">Create</span><span class="p">(</span><span class="m">0x42</span><span class="p">);</span>
</pre></td></tr></tbody></table></code></pre></div>  </div>

  <p>This will load up <code class="highlighter-rouge">someVector256</code> with 8 copies of <code class="highlighter-rouge">0x42</code> once executed, and in x64 assembly, the JIT will produce something quite simple:</p>

  <div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nf">vmovd</span>  <span class="nv">xmm0</span><span class="p">,</span> <span class="nb">rax</span>          <span class="c1">; 3 cycle latency / 1 cycle throughput</span>
<span class="nf">vpbroadcastd</span> <span class="nv">ymm0</span><span class="p">,</span> <span class="nv">xmm0</span>   <span class="c1">; 3 cycle latency / 1 cycle throughput</span>
</pre></td></tr></tbody></table></code></pre></div>  </div>

  <p>This specific intrinsic is translated into two intel opcodes, since there is no direct single instruction that performs this.</p>
</div>

<h4 id="avx2loaddquvector256--avxstore">Avx2.LoadDquVector256 / Avx.Store</h4>

<div>
  <div class="stickemup">
    <object class="animated-border" width="100%" type="image/svg+xml" data="../talks/intrinsics-sorting-2019/inst-animations/lddqu-with-hint.svg"></object>
  </div>

  <p>Next up we have a couple of brain dead simple intrinsics that we use to read/write from memory into SIMD registers and conversely store from SIMD registers back to memory. These are amongst the most common intrinsics out there, as you can imagine:</p>

  <div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="kt">int</span> <span class="p">*</span><span class="n">ptr</span> <span class="p">=</span> <span class="p">...;</span> <span class="c1">// Get some pointer to a big enough array</span>

<span class="n">Vector256</span><span class="p">&lt;</span><span class="kt">int</span><span class="p">&gt;</span> <span class="n">data</span> <span class="p">=</span> <span class="n">Avx</span><span class="p">.</span><span class="nf">LoadDquVector256</span><span class="p">(</span><span class="n">ptr</span><span class="p">);</span>
<span class="p">...</span>
<span class="n">Avx</span><span class="p">.</span><span class="nf">Store</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">data</span><span class="p">);</span>
</pre></td></tr></tbody></table></code></pre></div>  </div>

  <p>And in x64 assembly:</p>

  <div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="nf">vlddqu</span> <span class="nv">ymm1</span><span class="p">,</span> <span class="nv">ymmword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rdi</span><span class="p">]</span>  <span class="c1">; 5 cycle latency + cache/memory</span>
                                <span class="c1">; 0.5 cycle throughput</span>
<span class="nf">vmovdqu</span> <span class="nv">ymmword</span> <span class="nv">ptr</span> <span class="p">[</span><span class="nb">rdi</span><span class="p">],</span> <span class="nv">ymm1</span> <span class="c1">; Same as above</span>
</pre></td></tr></tbody></table></code></pre></div>  </div>

  <p>I only included an SVG animation for <code class="highlighter-rouge">LoadDquVector256</code>, but you can use your imagination and visualize how <code class="highlighter-rouge">Store</code> simply does the same thing in reverse.</p>
</div>

<h4 id="comparegreaterthan">CompareGreaterThan</h4>

<div>
  <div class="stickemup">
    <object class="animated-border" width="100%" type="image/svg+xml" data="../talks/intrinsics-sorting-2019/inst-animations/vpcmpgtd-with-hint.svg"></object>
  </div>

  <p><code class="highlighter-rouge">CompareGreaterThan</code> does an <em>n</em>-way, element-by-element <em>greater-than</em> (<code class="highlighter-rouge">&gt;</code>) comparison between two <code class="highlighter-rouge">Vector256&lt;T&gt;</code> instances. In our case where <code class="highlighter-rouge">T</code> is really <code class="highlighter-rouge">int</code>, this means comparing 8 integers in one go, instead of performing 8 comparisons serially!</p>

  <p>But where is the result? In a new <code class="highlighter-rouge">Vector256&lt;int&gt;</code> of course! The resulting vector contains 8 results for the corresponding comparisons between the elements of the first and second vectors. Each position where the element in the first vector was <em>greater-than</em> (<code class="highlighter-rouge">&gt;</code>) the second vector, the corresponding element in the result vector gets a <code class="highlighter-rouge">-1</code> value, or <code class="highlighter-rouge">0</code> otherwise.<br />
Calling this is rather simple:</p>

  <div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="n">Vector256</span><span class="p">&lt;</span><span class="kt">int</span><span class="p">&gt;</span> <span class="n">data</span><span class="p">,</span> <span class="n">comperand</span><span class="p">;</span>
<span class="n">Vector256</span><span class="p">&lt;</span><span class="kt">int</span><span class="p">&gt;</span> <span class="n">result</span> <span class="p">=</span>
    <span class="n">Avx2</span><span class="p">.</span><span class="nf">CompareGreaterThan</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">comperand</span><span class="p">);</span>
</pre></td></tr></tbody></table></code></pre></div>  </div>

  <p>And in x64 assembly, this is pretty simple too:</p>

  <div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nf">vpcmpgtd</span> <span class="nv">ymm2</span><span class="p">,</span> <span class="nv">ymm1</span><span class="p">,</span> <span class="nv">ymm0</span> <span class="c1">; 1 cycle latency</span>
                          <span class="c1">; 0.5 cycle throughput</span>
</pre></td></tr></tbody></table></code></pre></div>  </div>

</div>
<h4 id="movemask">MoveMask</h4>

<div>
  <div class="stickemup">
    <object class="animated-border" width="100%" type="image/svg+xml" data="../talks/intrinsics-sorting-2019/inst-animations/vmovmskps-with-hint.svg"></object>
  </div>

  <p>Another intrinsic which will prove to be very useful is the ability to extract some bits from a vectorized register into a normal, scalar one. <code class="highlighter-rouge">MoveMask</code> does just this. This intrinsic takes the top-level (MSB) bit from every element and moves it into our scalar result:</p>

  <div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">Vector256</span><span class="p">&lt;</span><span class="kt">int</span><span class="p">&gt;</span> <span class="n">data</span><span class="p">;</span>
<span class="kt">int</span> <span class="n">result</span> <span class="p">=</span> <span class="n">Avx</span><span class="p">.</span><span class="nf">MoveMask</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="nf">AsSingle</span><span class="p">());</span>
</pre></td></tr></tbody></table></code></pre></div>  </div>

  <p>There’s an oddity here, as you can tell by that awkward <code class="highlighter-rouge">.AsSingle()</code> call, try to ignore it if you can, or hit this footnote<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote">5</a></sup> if you can’t. The assembly instruction here is exactly as simple as you would think:</p>

  <div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nf">vmovmskps</span> <span class="nb">rax</span><span class="p">,</span> <span class="nv">ymm2</span>  <span class="c1">; 5 cycle latency</span>
                     <span class="c1">; 1 cycle throughput</span>
</pre></td></tr></tbody></table></code></pre></div>  </div>

</div>

<h4 id="popcount">PopCount</h4>

<p><code class="highlighter-rouge">PopCount</code> is a very powerful intrinsic, which <a href="/2018-08-19/netcoreapp3.0-intrinsics-in-real-life-pt2">I’ve covered extensively before</a>: <code class="highlighter-rouge">PopCount</code> returns the number of <code class="highlighter-rouge">1</code> bits in a 32/64 bit primitive.<br />
In C#, we would use it as follows:</p>

<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="kt">int</span> <span class="n">result</span> <span class="p">=</span> <span class="n">PopCnt</span><span class="p">.</span><span class="nf">PopCount</span><span class="p">(</span><span class="m">0</span><span class="n">b0000111100110011</span><span class="p">);</span>
<span class="c1">// result == 8</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>And in x64 assembly code:</p>

<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nf">popcnt</span> <span class="nb">rax</span><span class="p">,</span> <span class="nb">rdx</span>  <span class="c1">; 3 cycle latency</span>
                 <span class="c1">; 1 cycle throughput</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>In this series, <code class="highlighter-rouge">PopCount</code> is the only intrinsic I use that is not purely vectorized<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">6</a></sup>.</p>

<h4 id="permutevar8x32">PermuteVar8x32</h4>

<div>
  <div class="stickemup">
    <object class="animated-border" type="image/svg+xml" data="../talks/intrinsics-sorting-2019/inst-animations/vpermd-with-hint.svg"></object>
  </div>

  <p><code class="highlighter-rouge">PermuteVar8x32</code> accepts two vectors: source, permutation and performs a permutation operation <strong>on</strong> the source value <em>according to the order provided</em> in the permutation value. If this sounds confusing go straight to the visualization below…</p>

  <div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">Vector256</span><span class="p">&lt;</span><span class="kt">int</span><span class="p">&gt;</span> <span class="n">data</span><span class="p">,</span> <span class="n">perm</span><span class="p">;</span>
<span class="n">Vector256</span><span class="p">&lt;</span><span class="kt">int</span><span class="p">&gt;</span> <span class="n">result</span> <span class="p">=</span> <span class="n">Avx2</span><span class="p">.</span><span class="nf">PermuteVar8x32</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">perm</span><span class="p">);</span>
</pre></td></tr></tbody></table></code></pre></div>  </div>

  <p>While technically speaking, both the <code class="highlighter-rouge">data</code> and <code class="highlighter-rouge">perm</code> parameters are of type <code class="highlighter-rouge">Vector256&lt;int&gt;</code> and can contain any integer value in their elements, only the 3 least significant bits in <code class="highlighter-rouge">perm</code> are taken into account for permutation of the elements in <code class="highlighter-rouge">data</code>.<br />
This should make sense, as we are permuting an 8-element vector, so we need 3 bits (2<sup>3</sup> == 8) in every permutation element to figure out which element goes where… In x64 assembly this is:</p>

  <div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nf">vpermd</span> <span class="nv">ymm1</span><span class="p">,</span> <span class="nv">ymm2</span><span class="p">,</span> <span class="nv">ymm1</span> <span class="c1">; 3 cycles latency</span>
                        <span class="c1">; 1 cycles throughput</span>
</pre></td></tr></tbody></table></code></pre></div>  </div>

</div>

<h3 id="thats-it-for-now">That’s it for now</h3>

<p>This post was all about laying the groundwork before this whole mess comes together.<br />
Remember, we’re re-implementing QuickSort with AVX2 intrinsics in this series, which for the most part, means re-implementing the partitioning function from our scalar code listing in the previous post.<br />
I’m sure wheels are turning in many heads now as you are trying to figure out what comes next…<br />
I think it might be a good time as any to end this post and leave you with a suggestion: Try to take a piece of paper or your favorite text editor, and see if you can cobble up these instructions into something that can partition numbers given a selected pivot.</p>

<p>When you’re ready, head on to the <a href="/2020-01-30/this-goes-to-eleven-pt3">next post</a> to see how the whole thing comes together, and how fast we can get it to run with a basic version…</p>

<hr />

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:0" role="doc-endnote">
      <p>To be clear, some of these are intrinsics in unreleased processors, and even of those that are all released in the wild, there is no single processor support all of these… <a href="#fnref:0" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:1" role="doc-endnote">
      <p>CoreCLR supports roughly everything up to and including the AVX2 intrinsics, which were introduced with the  Intel Haswell processor, near the end of 2013. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>In general, auto-vectorizing compilers are a huge subject in their own, but the bottom line is that without completely changing the syntax and concepts of our programming language, there is very little that an auto-vectorizing compiler can do with existing code, and making one that really works often involves designing programming language with vectorization baked into them from day one. I really recommend reading <a href="https://pharr.org/matt/blog/2018/04/30/ispc-all.html">this series about Intel’s attempt</a> at this space if you are into this sort of thing. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Now, If I was in my annoyed state of mind, I’d bother to mention that <a href="https://github.com/dotnet/corefx/issues/2209#issuecomment-317124449">I personally always thought</a> that introducing 200+ functions with already established names (in C/C++/rust) and forcing everyone to learn new names whose only saving grace is that they look BCL<em>ish</em> to begin with was not the friendliest move on Microsoft’s part, and that trying to give C# names to the utter mess that Intel created in the first place was a thankless effort that would only annoy everyone more, and would eventually run up against the inhumane names Intel went for (Yes, I’m looking at you <code class="highlighter-rouge">LoadDquVector256</code>, you are not looking very BCL-ish to me with the <code class="highlighter-rouge">Dqu</code> slapped in the middle there : (╯°□°)╯︵ ┻━┻)… But thankfully, I’m not in my annoyed state. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>While this looks like we’re really doing “something” with our <code class="highlighter-rouge">Vector256&lt;int&gt;</code> and somehow casting it do single-precision floating point values, let me assure you, this is just smoke and mirrors: The intrinsic simply accepts only floating point values (32/64 bit ones), so we have to “cast” the data to <code class="highlighter-rouge">Vector256&lt;float&gt;</code>, or alternatively call <code class="highlighter-rouge">.AsSingle()</code> before calling <code class="highlighter-rouge">MoveMask</code>. Yes, this is super awkward from a pure C# perspective, but in reality, the JIT understands these shenanigans and really ignores them completely. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>By the way, although this intrinsic doesn’t accept nor return one of the SIMD registers / types, and considered to be a non-vectorized intrinsic as far as classification goes, as far as I’m concerned bit-level intrinsic functions that operate on scalar registers are just as “vectorized” as their “pure” vectorized sisters, as they mostly deal with scalar values as vectors of bits. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

        
      </section>

      <footer class="page__meta">
        
        


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2020-01-29T05:26:28+00:00">January 29, 2020</time></p>
        
      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=This+Goes+to+Eleven+%28Part.+2%2F%E2%88%9E%29%20https%3A%2F%2Fbits.houmus.org%2F2020-01-29%2Fthis-goes-to-eleven-pt2" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fbits.houmus.org%2F2020-01-29%2Fthis-goes-to-eleven-pt2" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fbits.houmus.org%2F2020-01-29%2Fthis-goes-to-eleven-pt2" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/2020-01-28/this-goes-to-eleven-pt1" class="pagination--pager" title="This Goes to Eleven (Part 1/∞)
">Previous</a>
    
    
      <a href="/2020-01-30/this-goes-to-eleven-pt3" class="pagination--pager" title="This Goes to Eleven (Part. 3/∞)
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2020-02-02/this-goes-to-eleven-pt5" rel="permalink">This Goes to Eleven (Pt. 5/∞)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  71 minute read

</p>
    
    <p class="archive__item-excerpt" itemprop="description">Decimating Array.Sort with AVX2. I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics. There’s no reason I should go down...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2020-02-01/this-goes-to-eleven-pt4" rel="permalink">This Goes to Eleven (Pt. 4/∞)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  56 minute read

</p>
    
    <p class="archive__item-excerpt" itemprop="description">Decimating Array.Sort with AVX2. I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics. There’s no reason I should go down...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2020-01-30/this-goes-to-eleven-pt3" rel="permalink">This Goes to Eleven (Part. 3/∞)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  79 minute read

</p>
    
    <p class="archive__item-excerpt" itemprop="description">Decimating Array.Sort with AVX2. I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics. There’s no reason I should go down...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/2020-01-28/this-goes-to-eleven-pt1" rel="permalink">This Goes to Eleven (Part 1/∞)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  39 minute read

</p>
    
    <p class="archive__item-excerpt" itemprop="description">Decimating Array.Sort with AVX2. I ended up going down the rabbit hole re-implementing array sorting with AVX2 intrinsics. There’s no reason I should go down...</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><div class="search-searchbar"></div>
  <div class="search-hits"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 damageboy. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>


<!-- Including InstantSearch.js library and styling -->
<script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch-theme-algolia.min.css">

<script>
// Instanciating InstantSearch.js with Algolia credentials
const search = instantsearch({
  appId: 'CMJJV3VL7A',
  apiKey: 'f1673463105fd4295fbbeffc415b5934',
  indexName: 'bits.houmus.org',
  searchParameters: {
    restrictSearchableAttributes: [
      'title',
      'content'
    ]
  }
});

const hitTemplate = function(hit) {
  const url = hit.url;
  const title = hit._highlightResult.title.value;
  const content = hit._highlightResult.html.value;

  return `
    <div class="list__item">
      <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
        <h2 class="archive__item-title" itemprop="headline"><a href="${url}">${title}</a></h2>
        <div class="archive__item-excerpt" itemprop="description">${content}</div>
      </article>
    </div>
  `;
}

// Adding searchbar and results widgets
search.addWidget(
  instantsearch.widgets.searchBox({
    container: '.search-searchbar',
    poweredBy: true,
    placeholder: 'Enter your search term...'
  })
);
search.addWidget(
  instantsearch.widgets.hits({
    container: '.search-hits',
    templates: {
      item: hitTemplate
    }
  })
);

// Starting the search
search.start();
</script>





  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-124434205-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-124434205-1', { 'anonymize_ip': false});
</script>








<div class="top-scroll-progress-bar"></div>


<script>
jQuery( document ).ready(function() {
    jQuery('table.datatable').each(function(){
        jQuery(this).datatable();
    });
});
</script>

<script>
  var element = document.documentElement,
    body = document.body,
    scrollTop = 'scrollTop',
    scrollHeight = 'scrollHeight',
    progress = document.querySelector('.top-scroll-progress-bar'),
    scroll;
  
  document.addEventListener('scroll', function() {
    scroll = (element[scrollTop]||body[scrollTop]) / ((element[scrollHeight]||body[scrollHeight]) - element.clientHeight) * 100;
    progress.style.setProperty('--scroll', scroll + '%');
  });
  </script>


  </body>
</html>
